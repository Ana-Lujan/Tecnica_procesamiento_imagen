{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCzuM5KzelH6"
      },
      "source": [
        "# UTILIDADES Y PLANTILLAS - LABORATORIO INTEGRADOR\n",
        "\n",
        "## Contenido\n",
        "Este cuaderno contiene **funciones de utilidad** y **plantillas de código** para usar en los laboratorios integradores.\n",
        "\n",
        "### Propósito:\n",
        "- **Acelerar el desarrollo** en los laboratorios\n",
        "- **Evitar repetir código** común\n",
        "- **Proporcionar ejemplos** de buenas prácticas\n",
        "- **Facilitar la experimentación** rápida\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvp_c95NelH8"
      },
      "source": [
        "## IMPORTACIONES ESTÁNDAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwkKRivKelH8"
      },
      "source": [
        "# ============================================\n",
        "# IMPORTACIONES ESTÁNDAR - COPIAR Y PEGAR\n",
        "# ============================================\n",
        "# Copiar y pegar este bloque en cualquier laboratorio\n",
        "\n",
        "# Procesamiento numérico y manipulación de datos\n",
        "import numpy as np          # Operaciones numéricas y arrays multidimensionales\n",
        "import pandas as pd         # Análisis y manipulación de datos estructurados\n",
        "\n",
        "# Bibliotecas de visualización\n",
        "import matplotlib.pyplot as plt    # Gráficos y visualizaciones básicas\n",
        "import seaborn as sns             # Visualizaciones estadísticas avanzadas\n",
        "\n",
        "# Procesamiento de imágenes - Bibliotecas principales\n",
        "from PIL import Image, ImageEnhance           # Python Imaging Library - carga y manipulación básica\n",
        "import cv2                                    # OpenCV - procesamiento avanzado (nota: usa BGR)\n",
        "from skimage import color, feature, measure, filters, morphology, segmentation  # Scikit-image - algoritmos especializados\n",
        "\n",
        "# Machine Learning y análisis predictivo\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder    # Preprocesamiento de datos\n",
        "from sklearn.model_selection import train_test_split             # División de datasets\n",
        "from sklearn.ensemble import RandomForestClassifier              # Algoritmo de clasificación\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Métricas de evaluación\n",
        "\n",
        "# Utilidades del sistema operativo\n",
        "import os        # Navegación de archivos y carpetas\n",
        "import glob      # Búsqueda de archivos con patrones\n",
        "import warnings  # Control de mensajes de advertencia\n",
        "warnings.filterwarnings('ignore')  # Suprimir advertencias para salida más limpia\n",
        "\n",
        "# Específico para Google Colab\n",
        "from google.colab import files    # Subida y descarga de archivos en Colab\n",
        "\n",
        "# Configuración global de matplotlib para gráficos más grandes y legibles\n",
        "plt.rcParams['figure.figsize'] = (12, 8)    # Tamaño por defecto de las figuras\n",
        "plt.rcParams['font.size'] = 10              # Tamaño de fuente por defecto\n",
        "\n",
        "# Semilla para reproducibilidad de resultados aleatorios\n",
        "np.random.seed(42)  # Garantiza que los resultados aleatorios sean consistentes\n",
        "\n",
        "print(\"✓ Importaciones cargadas correctamente\")\n",
        "print(\"✓ Configuración aplicada\")\n",
        "print(\"✓ Listo para comenzar el análisis\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16CBdmlOelH9"
      },
      "source": [
        "## UTILIDADES DE IMÁGENES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USj824w0elH-"
      },
      "source": [
        "# =============================================\n",
        "# UTILIDADES PARA MANEJO SEGURO DE IMÁGENES\n",
        "# =============================================\n",
        "\n",
        "def cargar_imagen_segura(path, target_size=None):\n",
        "    \"\"\"\n",
        "    Carga una imagen de forma segura con manejo completo de errores.\n",
        "    Convierte automáticamente a RGB y normaliza valores entre 0-1.\n",
        "\n",
        "    Args:\n",
        "        path (str): Ruta completa al archivo de imagen\n",
        "        target_size (tuple): Tupla (ancho, alto) para redimensionar la imagen\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Array normalizado (0-1) o None si hay error\n",
        "\n",
        "    Ejemplo:\n",
        "        img = cargar_imagen_segura('foto.jpg', target_size=(256, 256))\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Abrir imagen usando PIL (soporta múltiples formatos)\n",
        "        img = Image.open(path)\n",
        "\n",
        "        # Convertir a RGB si está en otro modo (RGBA, L, etc.)\n",
        "        # Esto garantiza consistencia en el número de canales\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        # Redimensionar si se especifica un tamaño objetivo\n",
        "        # LANCZOS ofrece mejor calidad para redimensionamiento\n",
        "        if target_size:\n",
        "            img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        # Convertir a numpy array y normalizar a rango [0,1]\n",
        "        # División por 255 convierte de uint8 [0,255] a float [0,1]\n",
        "        return np.array(img) / 255.0\n",
        "\n",
        "    except Exception as e:\n",
        "        # Capturar cualquier error (archivo no encontrado, formato no válido, etc.)\n",
        "        print(f\"Error cargando {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def mostrar_imagen_info(imagen, titulo=\"Imagen\"):\n",
        "    \"\"\"\n",
        "    Muestra información estadística completa de una imagen.\n",
        "    Útil para debugging y análisis exploratorio.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Array de la imagen\n",
        "        titulo (str): Título descriptivo para la salida\n",
        "\n",
        "    Ejemplo:\n",
        "        mostrar_imagen_info(mi_imagen, \"Imagen Original\")\n",
        "    \"\"\"\n",
        "    print(f\"{titulo.upper()}:\")\n",
        "    print(f\"   Shape: {imagen.shape}\")                    # Dimensiones (altura, ancho, canales)\n",
        "    print(f\"   Tipo de datos: {imagen.dtype}\")           # Tipo de datos (float64, uint8, etc.)\n",
        "    print(f\"   Rango de valores: [{imagen.min():.3f}, {imagen.max():.3f}]\")  # Min y max\n",
        "    print(f\"   Valor promedio: {imagen.mean():.3f}\")     # Media de todos los píxeles\n",
        "    print(f\"   Desviación estándar: {imagen.std():.3f}\") # Variabilidad de los valores\n",
        "\n",
        "def visualizar_canales_rgb(imagen, titulo=\"Análisis de Canales RGB\"):\n",
        "    \"\"\"\n",
        "    Visualiza los canales RGB de una imagen por separado.\n",
        "    Útil para entender la contribución de cada color primario.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB a analizar\n",
        "        titulo (str): Título para la visualización\n",
        "\n",
        "    Nota:\n",
        "        Cada canal se muestra con su colormap correspondiente para mejor interpretación.\n",
        "    \"\"\"\n",
        "    # Crear subplot con 4 columnas: original + 3 canales\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "    # Mostrar imagen original en color completo\n",
        "    axes[0].imshow(imagen)\n",
        "    axes[0].set_title('Imagen Completa (RGB)')\n",
        "    axes[0].axis('off')  # Ocultar ejes para mejor visualización\n",
        "\n",
        "    # Definir nombres y mapas de color para cada canal\n",
        "    canales = ['Rojo (R)', 'Verde (G)', 'Azul (B)']\n",
        "    colormaps = ['Reds', 'Greens', 'Blues']  # Mapas de color temáticos\n",
        "\n",
        "    # Mostrar cada canal individual\n",
        "    for i in range(3):\n",
        "        # Extraer canal específico ([:,:,i] selecciona el canal i)\n",
        "        axes[i+1].imshow(imagen[:,:,i], cmap=colormaps[i])\n",
        "        axes[i+1].set_title(f'Canal {canales[i]}')\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "    # Configurar layout y mostrar\n",
        "    plt.suptitle(titulo)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def convertir_espacios_color(imagen):\n",
        "    \"\"\"\n",
        "    Convierte una imagen RGB a múltiples espacios de color.\n",
        "    Útil para análisis comparativo y selección del espacio óptimo.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con diferentes representaciones de la imagen\n",
        "\n",
        "    Espacios incluidos:\n",
        "        - RGB: Red, Green, Blue (original)\n",
        "        - HSV: Hue (tono), Saturation (saturación), Value (valor)\n",
        "        - Grayscale: Escala de grises (luminancia)\n",
        "        - LAB: L*a*b* (perceptualmente uniforme)\n",
        "    \"\"\"\n",
        "    espacios = {\n",
        "        'rgb': imagen,                      # Espacio original\n",
        "        'hsv': color.rgb2hsv(imagen),       # Separación tono/saturación/brillo\n",
        "        'gray': color.rgb2gray(imagen),     # Información de luminancia únicamente\n",
        "        'lab': color.rgb2lab(imagen)        # Espacio perceptualmente uniforme\n",
        "    }\n",
        "\n",
        "    return espacios\n",
        "\n",
        "# Mensaje de confirmación para el usuario\n",
        "print(\"✓ Utilidades de imágenes definidas y documentadas\")\n",
        "print(\"  → cargar_imagen_segura(): Carga robusta con manejo de errores\")\n",
        "print(\"  → mostrar_imagen_info(): Estadísticas detalladas de la imagen\")\n",
        "print(\"  → visualizar_canales_rgb(): Separación visual de canales\")\n",
        "print(\"  → convertir_espacios_color(): Múltiples representaciones\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY9y9OwjelH_"
      },
      "source": [
        "## UTILIDADES DE SEGMENTACIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAfLFCJwelH_"
      },
      "source": [
        "# =========================================================\n",
        "# UTILIDADES AVANZADAS DE SEGMENTACIÓN DE IMÁGENES\n",
        "# =========================================================\n",
        "\n",
        "def segmentar_por_color_hsv_auto(imagen, num_colores=5):\n",
        "    \"\"\"\n",
        "    Segmentación automática usando clustering K-means en espacio HSV.\n",
        "    Agrupa píxeles similares por sus características de tono y saturación.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "        num_colores (int): Número de clusters (regiones) deseadas\n",
        "\n",
        "    Returns:\n",
        "        tuple: (máscara_segmentada, modelo_kmeans)\n",
        "        - máscara_segmentada: Array 2D con etiquetas de cluster por píxel\n",
        "        - modelo_kmeans: Objeto KMeans entrenado para reutilización\n",
        "\n",
        "    Ventaja del HSV: Separación natural entre tono (color) y brillo\n",
        "    \"\"\"\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # Convertir RGB a HSV para mejor separación de colores\n",
        "    # HSV separa información cromática (H,S) de luminancia (V)\n",
        "    imagen_hsv = color.rgb2hsv(imagen)\n",
        "\n",
        "    # Obtener dimensiones para reshape posterior\n",
        "    altura, ancho, _ = imagen_hsv.shape\n",
        "\n",
        "    # Usar solo canales H (tono) y S (saturación) para clustering\n",
        "    # El canal V (valor/brillo) puede variar por iluminación\n",
        "    pixeles_hs = imagen_hsv[:,:,:2].reshape(-1, 2)  # Reshape a (n_pixeles, 2)\n",
        "\n",
        "    # Aplicar K-means clustering\n",
        "    # random_state=42 garantiza resultados reproducibles\n",
        "    kmeans = KMeans(n_clusters=num_colores, random_state=42)\n",
        "    etiquetas = kmeans.fit_predict(pixeles_hs)\n",
        "\n",
        "    # Reformar etiquetas de vuelta a forma de imagen\n",
        "    segmentacion = etiquetas.reshape(altura, ancho)\n",
        "\n",
        "    return segmentacion, kmeans\n",
        "\n",
        "def crear_mascara_color_rango(imagen_hsv, h_min, h_max, s_min=0.2, v_min=0.2):\n",
        "    \"\"\"\n",
        "    Crea máscara binaria para segmentar un rango específico de colores.\n",
        "    Útil para detectar objetos de colores conocidos (ej: frutas, señales).\n",
        "\n",
        "    Args:\n",
        "        imagen_hsv (numpy.ndarray): Imagen en espacio HSV [0,1]\n",
        "        h_min, h_max (float): Rango de tono (Hue) [0,1]\n",
        "        s_min (float): Saturación mínima (evita colores desaturados)\n",
        "        v_min (float): Valor mínimo (evita píxeles muy oscuros)\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Máscara binaria (1 donde cumple condiciones, 0 donde no)\n",
        "\n",
        "    Ejemplo rangos de tono:\n",
        "        - Rojo: 0.0-0.1 y 0.9-1.0 (el rojo está en los extremos)\n",
        "        - Verde: 0.2-0.4\n",
        "        - Azul: 0.5-0.7\n",
        "    \"\"\"\n",
        "    # Crear máscaras individuales para cada condición\n",
        "    mask_h = (imagen_hsv[:,:,0] >= h_min) & (imagen_hsv[:,:,0] <= h_max)  # Rango de tono\n",
        "    mask_s = imagen_hsv[:,:,1] >= s_min  # Saturación mínima (evita grises)\n",
        "    mask_v = imagen_hsv[:,:,2] >= v_min  # Valor mínimo (evita negro/sombras)\n",
        "\n",
        "    # Combinar todas las condiciones con operador AND lógico\n",
        "    # Un píxel debe cumplir TODAS las condiciones para ser incluido\n",
        "    mask_final = mask_h & mask_s & mask_v\n",
        "\n",
        "    # Convertir boolean a uint8 para compatibilidad con OpenCV\n",
        "    return mask_final.astype(np.uint8)\n",
        "\n",
        "def limpiar_mascara_morfologia(mascara, tam_kernel=3, operaciones=['close', 'open']):\n",
        "    \"\"\"\n",
        "    Limpia máscaras binarias usando operaciones morfológicas.\n",
        "    Elimina ruido y conecta regiones fragmentadas.\n",
        "\n",
        "    Args:\n",
        "        mascara (numpy.ndarray): Máscara binaria a limpiar\n",
        "        tam_kernel (int): Tamaño del elemento estructurante (kernel)\n",
        "        operaciones (list): Lista de operaciones a aplicar en orden\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Máscara limpiada\n",
        "\n",
        "    Operaciones disponibles:\n",
        "        - 'close': Cierra huecos pequeños (dilatación + erosión)\n",
        "        - 'open': Elimina ruido pequeño (erosión + dilatación)\n",
        "        - 'erode': Reduce el tamaño de las regiones\n",
        "        - 'dilate': Expande las regiones\n",
        "    \"\"\"\n",
        "    from skimage.morphology import disk, closing, opening, erosion, dilation\n",
        "\n",
        "    # Crear elemento estructurante circular\n",
        "    # disk() crea un círculo que preserva mejor las formas naturales\n",
        "    kernel = disk(tam_kernel)\n",
        "    resultado = mascara.copy()\n",
        "\n",
        "    # Aplicar operaciones en el orden especificado\n",
        "    for op in operaciones:\n",
        "        if op == 'close':\n",
        "            # Closing: Conecta regiones cercanas y cierra huecos\n",
        "            resultado = closing(resultado, kernel)\n",
        "        elif op == 'open':\n",
        "            # Opening: Elimina regiones pequeñas (ruido)\n",
        "            resultado = opening(resultado, kernel)\n",
        "        elif op == 'erode':\n",
        "            # Erosión: Reduce tamaño de regiones (adelgaza bordes)\n",
        "            resultado = erosion(resultado, kernel)\n",
        "        elif op == 'dilate':\n",
        "            # Dilatación: Expande regiones (engrosa bordes)\n",
        "            resultado = dilation(resultado, kernel)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def analizar_regiones_conectadas(mascara_binaria, min_area=50):\n",
        "    \"\"\"\n",
        "    Identifica y analiza objetos individuales en una máscara binaria.\n",
        "    Extrae propiedades geométricas de cada región conectada.\n",
        "\n",
        "    Args:\n",
        "        mascara_binaria (numpy.ndarray): Máscara binaria con objetos\n",
        "        min_area (int): Área mínima en píxeles para considerar un objeto\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de objetos regionprops con propiedades geométricas\n",
        "\n",
        "    Propiedades útiles de cada región:\n",
        "        - .area: Área en píxeles\n",
        "        - .bbox: Bounding box (min_row, min_col, max_row, max_col)\n",
        "        - .centroid: Centro de masa\n",
        "        - .eccentricity: Excentricidad (0=círculo, 1=línea)\n",
        "        - .perimeter: Perímetro\n",
        "    \"\"\"\n",
        "    # Etiquetar regiones conectadas (componentes conectados)\n",
        "    # Cada objeto recibe una etiqueta numérica única\n",
        "    etiquetas = measure.label(mascara_binaria)\n",
        "\n",
        "    # Extraer propiedades geométricas de cada región\n",
        "    # regionprops calcula múltiples características automáticamente\n",
        "    regiones = measure.regionprops(etiquetas)\n",
        "\n",
        "    # Filtrar regiones muy pequeñas (probablemente ruido)\n",
        "    regiones_filtradas = [r for r in regiones if r.area >= min_area]\n",
        "\n",
        "    return regiones_filtradas\n",
        "\n",
        "def dibujar_bounding_boxes(ax, regiones, color='red', alpha=0.8):\n",
        "    \"\"\"\n",
        "    Dibuja rectángulos delimitadores (bounding boxes) alrededor de objetos detectados.\n",
        "    Útil para visualizar resultados de detección de objetos.\n",
        "\n",
        "    Args:\n",
        "        ax (matplotlib.axes): Eje donde dibujar los rectángulos\n",
        "        regiones (list): Lista de objetos regionprops\n",
        "        color (str): Color de los rectángulos\n",
        "        alpha (float): Transparencia (0=transparente, 1=opaco)\n",
        "\n",
        "    Nota: Debe llamarse después de ax.imshow() y antes de plt.show()\n",
        "    \"\"\"\n",
        "    import matplotlib.patches as patches\n",
        "\n",
        "    # Iterar sobre cada región detectada\n",
        "    for region in regiones:\n",
        "        # Obtener bounding box: (min_row, min_col, max_row, max_col)\n",
        "        bbox = region.bbox\n",
        "\n",
        "        # Crear rectángulo para matplotlib\n",
        "        # Nota: matplotlib usa (x,y) = (col,row), por eso se invierten las coordenadas\n",
        "        rect = patches.Rectangle(\n",
        "            (bbox[1], bbox[0]),           # Esquina inferior izquierda (x,y)\n",
        "            bbox[3] - bbox[1],            # Ancho (max_col - min_col)\n",
        "            bbox[2] - bbox[0],            # Alto (max_row - min_row)\n",
        "            linewidth=2,                  # Grosor del borde\n",
        "            edgecolor=color,              # Color del borde\n",
        "            facecolor='none',             # Sin relleno (solo borde)\n",
        "            alpha=alpha                   # Transparencia\n",
        "        )\n",
        "\n",
        "        # Agregar rectángulo al eje\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"✓ Utilidades de segmentación definidas y documentadas\")\n",
        "print(\"  → segmentar_por_color_hsv_auto(): Clustering automático en HSV\")\n",
        "print(\"  → crear_mascara_color_rango(): Segmentación por rango de color\")\n",
        "print(\"  → limpiar_mascara_morfologia(): Limpieza morfológica de máscaras\")\n",
        "print(\"  → analizar_regiones_conectadas(): Detección de objetos individuales\")\n",
        "print(\"  → dibujar_bounding_boxes(): Visualización de detecciones\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0igfUAqelIA"
      },
      "source": [
        "## UTILIDADES DE EXTRACCIÓN DE CARACTERÍSTICAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtbH3zToelIA"
      },
      "source": [
        "# ==============================================================\n",
        "# EXTRACCIÓN AVANZADA DE CARACTERÍSTICAS PARA MACHINE LEARNING\n",
        "# ==============================================================\n",
        "\n",
        "def extraer_estadisticas_basicas(imagen_canal):\n",
        "    \"\"\"\n",
        "    Extrae estadísticas descriptivas fundamentales de un canal de imagen.\n",
        "    Estas métricas capturan la distribución de intensidades en la imagen.\n",
        "\n",
        "    Args:\n",
        "        imagen_canal (numpy.ndarray): Canal individual de imagen (2D array)\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con estadísticas básicas\n",
        "\n",
        "    Estadísticas calculadas:\n",
        "        - Media: Intensidad promedio (indica brillo general)\n",
        "        - Desviación estándar: Variabilidad de intensidades (indica contraste)\n",
        "        - Mediana: Valor central (robusto a valores atípicos)\n",
        "        - Cuartiles: Q25 y Q75 (rango intercuartílico)\n",
        "        - Mínimo/Máximo: Rango completo de valores\n",
        "    \"\"\"\n",
        "    # Aplanar imagen a vector 1D para cálculos estadísticos\n",
        "    datos = imagen_canal.flatten()\n",
        "\n",
        "    # Calcular estadísticas descriptivas\n",
        "    estadisticas = {\n",
        "        'media': np.mean(datos),              # Promedio aritmético\n",
        "        'std': np.std(datos),                 # Desviación estándar (medida de dispersión)\n",
        "        'mediana': np.median(datos),          # Valor del percentil 50\n",
        "        'q25': np.percentile(datos, 25),      # Primer cuartil\n",
        "        'q75': np.percentile(datos, 75),      # Tercer cuartil\n",
        "        'min': np.min(datos),                 # Valor mínimo\n",
        "        'max': np.max(datos)                  # Valor máximo\n",
        "    }\n",
        "\n",
        "    return estadisticas\n",
        "\n",
        "def extraer_features_color_completas(imagen):\n",
        "    \"\"\"\n",
        "    Extrae características completas de color en espacios RGB y HSV.\n",
        "    Combina información cromática de ambos espacios para mayor robustez.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector de características de color (15 elementos)\n",
        "\n",
        "    Características extraídas:\n",
        "        RGB: 9 features (media, std, mediana por canal R, G, B)\n",
        "        HSV: 6 features (media, std por canal H, S, V)\n",
        "        Total: 15 características de color\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # CARACTERÍSTICAS RGB (3 canales × 3 estadísticas = 9 features)\n",
        "    for canal in range(3):\n",
        "        stats = extraer_estadisticas_basicas(imagen[:,:,canal])\n",
        "        # Seleccionar las 3 estadísticas más informativas por canal\n",
        "        features.extend([stats['media'], stats['std'], stats['mediana']])\n",
        "\n",
        "    # CARACTERÍSTICAS HSV (separación cromática/luminancia)\n",
        "    imagen_hsv = color.rgb2hsv(imagen)\n",
        "    for canal in range(3):\n",
        "        stats = extraer_estadisticas_basicas(imagen_hsv[:,:,canal])\n",
        "        # HSV: solo media y std son más relevantes (mediana menos informativa)\n",
        "        features.extend([stats['media'], stats['std']])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extraer_features_textura_avanzadas(imagen):\n",
        "    \"\"\"\n",
        "    Extrae características avanzadas de textura usando filtros de gradiente.\n",
        "    Captura información sobre patrones, bordes y rugosidad de la superficie.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB o escala de grises\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector de características de textura (7 elementos)\n",
        "\n",
        "    Técnicas utilizadas:\n",
        "        - Filtros de Sobel: Detectan gradientes horizontales y verticales\n",
        "        - Detector de Canny: Identifica bordes bien definidos\n",
        "        - Estadísticas de intensidad: Propiedades básicas de luminancia\n",
        "    \"\"\"\n",
        "    # Convertir a escala de grises si es necesario (textura no necesita color)\n",
        "    if len(imagen.shape) == 3:\n",
        "        imagen_gray = color.rgb2gray(imagen)\n",
        "    else:\n",
        "        imagen_gray = imagen\n",
        "\n",
        "    features = []\n",
        "\n",
        "    # FILTROS DE SOBEL para detección de gradientes\n",
        "    # Sobel horizontal: detecta cambios verticales (líneas horizontales)\n",
        "    sobel_h = filters.sobel_h(imagen_gray)\n",
        "    # Sobel vertical: detecta cambios horizontales (líneas verticales)\n",
        "    sobel_v = filters.sobel_v(imagen_gray)\n",
        "\n",
        "    # Estadísticas de gradientes (intensidad y variabilidad de bordes)\n",
        "    features.extend([\n",
        "        np.mean(np.abs(sobel_h)),    # Intensidad promedio de gradiente horizontal\n",
        "        np.mean(np.abs(sobel_v)),    # Intensidad promedio de gradiente vertical\n",
        "        np.std(sobel_h),             # Variabilidad de gradiente horizontal\n",
        "        np.std(sobel_v)              # Variabilidad de gradiente vertical\n",
        "    ])\n",
        "\n",
        "    # DETECTOR DE CANNY para bordes bien definidos\n",
        "    # Canny es más selectivo que Sobel (menos ruido, bordes más limpios)\n",
        "    bordes = feature.canny(imagen_gray)\n",
        "    # Densidad de bordes: proporción de píxeles que son borde\n",
        "    features.append(np.sum(bordes) / bordes.size)\n",
        "\n",
        "    # CARACTERÍSTICAS DE INTENSIDAD básicas\n",
        "    features.extend([\n",
        "        np.mean(imagen_gray),        # Brillo promedio\n",
        "        np.std(imagen_gray)          # Contraste general\n",
        "    ])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def calcular_histograma_color(imagen, bins=32):\n",
        "    \"\"\"\n",
        "    Calcula histograma concatenado de los 3 canales RGB.\n",
        "    Los histogramas capturan la distribución de colores en la imagen.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB [0,1]\n",
        "        bins (int): Número de bins por canal (resolución del histograma)\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Histograma concatenado normalizado (bins×3 elementos)\n",
        "\n",
        "    Normalización: Cada histograma suma 1.0 (distribución de probabilidad)\n",
        "    Ventaja: Invariante al tamaño de la imagen\n",
        "    \"\"\"\n",
        "    histograma = []\n",
        "\n",
        "    # Procesar cada canal RGB por separado\n",
        "    for canal in range(3):\n",
        "        # Calcular histograma en el rango [0,1] (imágenes normalizadas)\n",
        "        hist, _ = np.histogram(imagen[:,:,canal], bins=bins, range=(0, 1))\n",
        "\n",
        "        # Normalizar para que sume 1 (convertir a probabilidades)\n",
        "        hist = hist / np.sum(hist)\n",
        "        histograma.extend(hist)\n",
        "\n",
        "    return np.array(histograma)\n",
        "\n",
        "def extraer_features_completas(imagen):\n",
        "    \"\"\"\n",
        "    Combina TODAS las características disponibles en un vector único.\n",
        "    Esta función integra color, textura e histograma para máxima información.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector completo de características\n",
        "\n",
        "    Composición del vector:\n",
        "        - Características de color: 15 elementos (RGB + HSV)\n",
        "        - Características de textura: 7 elementos (gradientes + bordes)\n",
        "        - Histograma reducido: 24 elementos (8 bins × 3 canales)\n",
        "        Total: 46 características por imagen\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # BLOQUE 1: Características de color (RGB + HSV)\n",
        "    features_color = extraer_features_color_completas(imagen)\n",
        "    features.extend(features_color)\n",
        "\n",
        "    # BLOQUE 2: Características de textura (gradientes y bordes)\n",
        "    features_textura = extraer_features_textura_avanzadas(imagen)\n",
        "    features.extend(features_textura)\n",
        "\n",
        "    # BLOQUE 3: Histograma compacto (reducido para evitar sobreajuste)\n",
        "    # 8 bins por canal = 24 features totales (balance información/dimensionalidad)\n",
        "    histograma = calcular_histograma_color(imagen, bins=8)\n",
        "    features.extend(histograma)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"✓ Utilidades de extracción de características definidas y documentadas\")\n",
        "print(\"  → extraer_estadisticas_basicas(): Estadísticas descriptivas por canal\")\n",
        "print(\"  → extraer_features_color_completas(): Características RGB + HSV\")\n",
        "print(\"  → extraer_features_textura_avanzadas(): Gradientes y detección de bordes\")\n",
        "print(\"  → calcular_histograma_color(): Histogramas normalizados por canal\")\n",
        "print(\"  → extraer_features_completas(): Vector integrado de 46 características\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBwKKn9delIB"
      },
      "source": [
        "## UTILIDADES DE MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MabkDIfrelIC"
      },
      "source": [
        "# ===========================================================\n",
        "# UTILIDADES COMPLETAS PARA MACHINE LEARNING EN IMÁGENES\n",
        "# ===========================================================\n",
        "\n",
        "def preparar_datos_ml(X, y, test_size=0.2, val_size=0.2):\n",
        "    \"\"\"\n",
        "    Prepara datos para entrenamiento de ML con división estratificada en train/val/test.\n",
        "    Incluye codificación de etiquetas y normalización de características.\n",
        "\n",
        "    Args:\n",
        "        X (array-like): Matriz de características (n_muestras, n_features)\n",
        "        y (array-like): Vector de etiquetas (puede ser string o numérico)\n",
        "        test_size (float): Proporción para conjunto de prueba (0.2 = 20%)\n",
        "        val_size (float): Proporción de train para validación (0.2 = 20% del 80% restante)\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con conjuntos preparados y objetos de preprocesamiento\n",
        "\n",
        "    Conjuntos generados:\n",
        "        - Train: 60% de datos (para entrenar modelo)\n",
        "        - Validation: 20% de datos (para ajuste de hiperparámetros)\n",
        "        - Test: 20% de datos (para evaluación final)\n",
        "    \"\"\"\n",
        "    # CODIFICACIÓN DE ETIQUETAS (si son texto)\n",
        "    # Convertir categorías string a números enteros\n",
        "    if isinstance(y[0], str):\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "        print(f\"✓ Etiquetas codificadas: {list(label_encoder.classes_)}\")\n",
        "    else:\n",
        "        y_encoded = y\n",
        "        label_encoder = None\n",
        "        print(\"✓ Etiquetas numéricas detectadas (sin codificación)\")\n",
        "\n",
        "    # PRIMERA DIVISIÓN: Train (80%) + Test (20%)\n",
        "    # stratify=y_encoded mantiene proporción de clases en ambos conjuntos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded,\n",
        "        test_size=test_size,        # 20% para test\n",
        "        random_state=42,           # Reproducibilidad\n",
        "        stratify=y_encoded         # Mantener distribución de clases\n",
        "    )\n",
        "\n",
        "    # SEGUNDA DIVISIÓN: Train (60%) + Validation (20%)\n",
        "    # val_size se aplica sobre el conjunto de entrenamiento temporal\n",
        "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
        "        X_train, y_train,\n",
        "        test_size=val_size,        # 20% del 80% restante = 16% total → ajustado a 25% para obtener 20% final\n",
        "        random_state=42,\n",
        "        stratify=y_train\n",
        "    )\n",
        "\n",
        "    # NORMALIZACIÓN DE CARACTERÍSTICAS\n",
        "    # StandardScaler: media=0, desviación=1 para cada característica\n",
        "    # Importante: fit solo en train, transform en todos los conjuntos\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_final)  # Fit + transform en train\n",
        "    X_val_scaled = scaler.transform(X_val)                # Solo transform en val\n",
        "    X_test_scaled = scaler.transform(X_test)              # Solo transform en test\n",
        "\n",
        "    # PREPARAR RESULTADO\n",
        "    resultado = {\n",
        "        # Conjuntos de datos normalizados\n",
        "        'X_train': X_train_scaled,\n",
        "        'X_val': X_val_scaled,\n",
        "        'X_test': X_test_scaled,\n",
        "        # Etiquetas correspondientes\n",
        "        'y_train': y_train_final,\n",
        "        'y_val': y_val,\n",
        "        'y_test': y_test,\n",
        "        # Objetos de preprocesamiento (para nuevas predicciones)\n",
        "        'scaler': scaler,\n",
        "        'label_encoder': label_encoder\n",
        "    }\n",
        "\n",
        "    # REPORTE DE DIMENSIONES\n",
        "    print(f\"\\n✓ Conjuntos de datos preparados:\")\n",
        "    print(f\"   • Train: {X_train_scaled.shape[0]} muestras ({X_train_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   • Validation: {X_val_scaled.shape[0]} muestras ({X_val_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   • Test: {X_test_scaled.shape[0]} muestras ({X_test_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   • Características: {X_train_scaled.shape[1]} features por muestra\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def entrenar_modelo_rapido(datos, modelo=None):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de clasificación con evaluación automática.\n",
        "    Útil para prototipos rápidos y validación de características.\n",
        "\n",
        "    Args:\n",
        "        datos (dict): Diccionario retornado por preparar_datos_ml()\n",
        "        modelo (sklearn.base.BaseEstimator): Modelo a entrenar (opcional)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modelo_entrenado, predicciones_val, predicciones_test)\n",
        "\n",
        "    Modelo por defecto: RandomForest (robusto, interpretable, buen rendimiento)\n",
        "    \"\"\"\n",
        "    # Usar RandomForest si no se especifica modelo\n",
        "    # RF es robusto a overfitting y funciona bien sin mucho tuning\n",
        "    if modelo is None:\n",
        "        modelo = RandomForestClassifier(\n",
        "            n_estimators=100,      # 100 árboles (balance velocidad/rendimiento)\n",
        "            random_state=42,       # Reproducibilidad\n",
        "            max_depth=10,          # Limitar profundidad (evitar overfitting)\n",
        "            min_samples_split=5    # Mínimo de muestras para dividir nodo\n",
        "        )\n",
        "        print(\"✓ Usando RandomForest por defecto\")\n",
        "    else:\n",
        "        print(f\"✓ Usando modelo personalizado: {type(modelo).__name__}\")\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    print(\"⏳ Entrenando modelo...\")\n",
        "    modelo.fit(datos['X_train'], datos['y_train'])\n",
        "\n",
        "    # PREDICCIONES\n",
        "    # Validación: para ajuste de hiperparámetros\n",
        "    y_pred_val = modelo.predict(datos['X_val'])\n",
        "    # Test: para evaluación final (solo se usa una vez)\n",
        "    y_pred_test = modelo.predict(datos['X_test'])\n",
        "\n",
        "    # MÉTRICAS DE RENDIMIENTO\n",
        "    acc_val = accuracy_score(datos['y_val'], y_pred_val)\n",
        "    acc_test = accuracy_score(datos['y_test'], y_pred_test)\n",
        "\n",
        "    print(f\"\\n✓ Entrenamiento completado:\")\n",
        "    print(f\"   • Accuracy en Validación: {acc_val:.3f} ({acc_val*100:.1f}%)\")\n",
        "    print(f\"   • Accuracy en Test: {acc_test:.3f} ({acc_test*100:.1f}%)\")\n",
        "\n",
        "    # Interpretación automática de resultados\n",
        "    if acc_val > 0.9:\n",
        "        print(\"   → Excelente rendimiento\")\n",
        "    elif acc_val > 0.8:\n",
        "        print(\"   → Buen rendimiento\")\n",
        "    elif acc_val > 0.7:\n",
        "        print(\"   → Rendimiento aceptable\")\n",
        "    else:\n",
        "        print(\"   → Rendimiento bajo - revisar características o modelo\")\n",
        "\n",
        "    # Warning sobre overfitting\n",
        "    if (acc_val - acc_test) > 0.1:\n",
        "        print(\"   ⚠️  Posible overfitting (gran diferencia val-test)\")\n",
        "\n",
        "    return modelo, y_pred_val, y_pred_test\n",
        "\n",
        "def mostrar_matriz_confusion(y_true, y_pred, labels=None, title=\"Matriz de Confusión\"):\n",
        "    \"\"\"\n",
        "    Visualiza matriz de confusión con formato profesional.\n",
        "    Permite identificar errores de clasificación por clase.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Etiquetas reales\n",
        "        y_pred (array-like): Etiquetas predichas\n",
        "        labels (list): Nombres de clases para ejes (opcional)\n",
        "        title (str): Título del gráfico\n",
        "\n",
        "    La matriz muestra:\n",
        "        - Diagonal: Clasificaciones correctas\n",
        "        - Fuera de diagonal: Errores de clasificación\n",
        "    \"\"\"\n",
        "    # Calcular matriz de confusión\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Crear visualización con seaborn (más elegante que matplotlib básico)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Heatmap con anotaciones numéricas\n",
        "    sns.heatmap(cm,\n",
        "                annot=True,           # Mostrar números en celdas\n",
        "                fmt='d',              # Formato entero\n",
        "                cmap='Blues',         # Escala de colores azul\n",
        "                xticklabels=labels,   # Etiquetas eje X\n",
        "                yticklabels=labels,   # Etiquetas eje Y\n",
        "                cbar_kws={'label': 'Número de muestras'})\n",
        "\n",
        "    # Configuración de ejes y título\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicción del Modelo', fontsize=12)\n",
        "    plt.ylabel('Valor Real', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calcular métricas adicionales de la matriz\n",
        "    total_muestras = np.sum(cm)\n",
        "    aciertos = np.trace(cm)  # Suma de la diagonal\n",
        "    print(f\"\\n📊 Análisis de la matriz:\")\n",
        "    print(f\"   • Total de muestras: {total_muestras}\")\n",
        "    print(f\"   • Aciertos totales: {aciertos}\")\n",
        "    print(f\"   • Errores totales: {total_muestras - aciertos}\")\n",
        "\n",
        "def mostrar_importancia_features(modelo, feature_names=None, top_n=10):\n",
        "    \"\"\"\n",
        "    Visualiza importancia de características para modelos basados en árboles.\n",
        "    Ayuda a entender qué características son más relevantes para la clasificación.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo entrenado con atributo feature_importances_\n",
        "        feature_names (list): Nombres de características (opcional)\n",
        "        top_n (int): Número de características más importantes a mostrar\n",
        "\n",
        "    Solo funciona con: RandomForest, ExtraTrees, GradientBoosting, etc.\n",
        "    \"\"\"\n",
        "    # Verificar si el modelo soporta importancia de características\n",
        "    if hasattr(modelo, 'feature_importances_'):\n",
        "        importancias = modelo.feature_importances_\n",
        "\n",
        "        # Obtener índices de las características más importantes\n",
        "        indices = np.argsort(importancias)[-top_n:]  # Top N (orden ascendente)\n",
        "\n",
        "        # Crear nombres por defecto si no se proporcionan\n",
        "        if feature_names is None:\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importancias))]\n",
        "\n",
        "        # Crear gráfico horizontal (mejor para nombres largos)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(range(len(indices)), importancias[indices], color='skyblue', alpha=0.8)\n",
        "\n",
        "        # Configurar ejes\n",
        "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "        plt.xlabel('Importancia Relativa', fontsize=12)\n",
        "        plt.title(f'Top {top_n} Características Más Importantes', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Agregar valores en las barras\n",
        "        for i, v in enumerate(importancias[indices]):\n",
        "            plt.text(v + 0.001, i, f'{v:.3f}', va='center', fontsize=10)\n",
        "\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Mostrar valores numéricos también\n",
        "        print(f\"\\n🔍 Top {top_n} características más importantes:\")\n",
        "        for i, idx in enumerate(reversed(indices)):  # Orden descendente\n",
        "            print(f\"   {i+1:2d}. {feature_names[idx]:<30} {importancias[idx]:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ El modelo {type(modelo).__name__} no soporta importancia de características\")\n",
        "        print(\"   Modelos compatibles: RandomForest, ExtraTrees, GradientBoosting\")\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"✓ Utilidades de Machine Learning definidas y documentadas\")\n",
        "print(\"  → preparar_datos_ml(): División estratificada train/val/test + normalización\")\n",
        "print(\"  → entrenar_modelo_rapido(): Entrenamiento con evaluación automática\")\n",
        "print(\"  → mostrar_matriz_confusion(): Visualización profesional de errores\")\n",
        "print(\"  → mostrar_importancia_features(): Análisis de relevancia de características\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk--75yjelIC"
      },
      "source": [
        "## UTILIDADES DE VISUALIZACIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L74aS5PrelIC"
      },
      "source": [
        "# ====================================================\n",
        "# UTILIDADES AVANZADAS DE VISUALIZACIÓN\n",
        "# ====================================================\n",
        "\n",
        "def crear_grid_imagenes(imagenes, titulos=None, filas=2, figsize=(15, 8)):\n",
        "    \"\"\"\n",
        "    Crea un grid organizado de imágenes para comparación visual.\n",
        "    Útil para mostrar múltiples imágenes en una sola figura.\n",
        "\n",
        "    Args:\n",
        "        imagenes (list): Lista de arrays de imágenes\n",
        "        titulos (list): Lista de títulos para cada imagen (opcional)\n",
        "        filas (int): Número de filas en el grid\n",
        "        figsize (tuple): Tamaño de la figura (ancho, alto)\n",
        "\n",
        "    Maneja automáticamente:\n",
        "        - Imágenes en escala de grises (2D arrays)\n",
        "        - Imágenes en color (3D arrays)\n",
        "        - Grids irregulares (espacios vacíos)\n",
        "    \"\"\"\n",
        "    n_imagenes = len(imagenes)\n",
        "    # Calcular columnas necesarias basado en número de imágenes y filas\n",
        "    columnas = int(np.ceil(n_imagenes / filas))\n",
        "\n",
        "    # Crear subplot grid\n",
        "    fig, axes = plt.subplots(filas, columnas, figsize=figsize)\n",
        "\n",
        "    # Manejar caso especial de una sola imagen\n",
        "    if n_imagenes == 1:\n",
        "        axes = [axes]\n",
        "    elif filas == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    elif columnas == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    # Aplanar array de axes para fácil iteración\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Mostrar cada imagen\n",
        "    for i, img in enumerate(imagenes):\n",
        "        # Detectar si es escala de grises o color\n",
        "        if len(img.shape) == 2:  # Escala de grises\n",
        "            axes[i].imshow(img, cmap='gray')\n",
        "        else:  # Color (RGB)\n",
        "            axes[i].imshow(img)\n",
        "\n",
        "        # Agregar título si se proporciona\n",
        "        if titulos and i < len(titulos):\n",
        "            axes[i].set_title(titulos[i], fontsize=12)\n",
        "\n",
        "        # Ocultar ejes para mejor visualización\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Ocultar axes sobrantes en caso de grid irregular\n",
        "    for i in range(n_imagenes, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def mostrar_antes_despues(img_original, img_procesada, titulo_original=\"Original\", titulo_procesada=\"Procesada\"):\n",
        "    \"\"\"\n",
        "    Muestra comparación lado a lado de imagen original vs procesada.\n",
        "    Perfecto para visualizar el efecto de operaciones de procesamiento.\n",
        "\n",
        "    Args:\n",
        "        img_original (numpy.ndarray): Imagen antes del procesamiento\n",
        "        img_procesada (numpy.ndarray): Imagen después del procesamiento\n",
        "        titulo_original (str): Título para imagen original\n",
        "        titulo_procesada (str): Título para imagen procesada\n",
        "    \"\"\"\n",
        "    # Crear subplot con 2 columnas\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Mostrar imagen original\n",
        "    ax1.imshow(img_original)\n",
        "    ax1.set_title(titulo_original, fontsize=14, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Mostrar imagen procesada (detectar si es escala de grises)\n",
        "    if len(img_procesada.shape) == 2:\n",
        "        ax2.imshow(img_procesada, cmap='gray')\n",
        "    else:\n",
        "        ax2.imshow(img_procesada)\n",
        "    ax2.set_title(titulo_procesada, fontsize=14, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def crear_dashboard_imagen(imagen, mostrar_canales=True, mostrar_histograma=True, mostrar_estadisticas=True):\n",
        "    \"\"\"\n",
        "    Crea un dashboard completo de análisis visual de imagen.\n",
        "    Combina múltiples visualizaciones en una sola figura integral.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB a analizar\n",
        "        mostrar_canales (bool): Mostrar separación de canales RGB\n",
        "        mostrar_histograma (bool): Mostrar histograma de intensidades\n",
        "        mostrar_estadisticas (bool): Mostrar panel de estadísticas\n",
        "\n",
        "    Genera:\n",
        "        - Imagen original\n",
        "        - Canales RGB separados\n",
        "        - Histograma de distribución de colores\n",
        "        - Panel de estadísticas descriptivas\n",
        "    \"\"\"\n",
        "    # Crear figura grande con subplot grid\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Imagen original (posición principal)\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title('Imagen Original', fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    if mostrar_canales and len(imagen.shape) == 3:\n",
        "        # Canales RGB individuales\n",
        "        canales = ['Rojo', 'Verde', 'Azul']\n",
        "        cmaps = ['Reds', 'Greens', 'Blues']\n",
        "\n",
        "        for i in range(3):\n",
        "            ax = plt.subplot(3, 3, i + 2)\n",
        "            plt.imshow(imagen[:,:,i], cmap=cmaps[i])\n",
        "            plt.title(f'Canal {canales[i]}', fontsize=12)\n",
        "            plt.axis('off')\n",
        "\n",
        "    if mostrar_histograma:\n",
        "        # Histograma de distribución de colores\n",
        "        ax5 = plt.subplot(3, 3, 5)\n",
        "        if len(imagen.shape) == 3:\n",
        "            colors = ['red', 'green', 'blue']\n",
        "            # Histograma superpuesto para cada canal\n",
        "            for i in range(3):\n",
        "                plt.hist(imagen[:,:,i].flatten(), bins=50, alpha=0.6,\n",
        "                        color=colors[i], label=canales[i])\n",
        "            plt.legend()\n",
        "        else:\n",
        "            plt.hist(imagen.flatten(), bins=50, alpha=0.7, color='gray')\n",
        "\n",
        "        plt.title('Histograma de Intensidades', fontsize=12)\n",
        "        plt.xlabel('Intensidad')\n",
        "        plt.ylabel('Frecuencia')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "    if mostrar_estadisticas:\n",
        "        # Panel de estadísticas descriptivas\n",
        "        ax6 = plt.subplot(3, 3, 6)\n",
        "        ax6.axis('off')  # Sin ejes para texto puro\n",
        "\n",
        "        # Compilar texto estadístico\n",
        "        stats_text = \"📊 ESTADÍSTICAS:\\n\\n\"\n",
        "        stats_text += f\"📐 Dimensiones: {imagen.shape}\\n\"\n",
        "        stats_text += f\"🔢 Tipo de datos: {imagen.dtype}\\n\"\n",
        "        stats_text += f\"📉 Rango: [{imagen.min():.3f}, {imagen.max():.3f}]\\n\"\n",
        "        stats_text += f\"📊 Media global: {imagen.mean():.3f}\\n\"\n",
        "        stats_text += f\"📈 Desv. estándar: {imagen.std():.3f}\\n\\n\"\n",
        "\n",
        "        # Estadísticas por canal si es color\n",
        "        if len(imagen.shape) == 3:\n",
        "            stats_text += \"🎨 POR CANAL:\\n\"\n",
        "            canales_nombres = ['🔴 Rojo', '🟢 Verde', '🔵 Azul']\n",
        "            for i in range(3):\n",
        "                canal_mean = imagen[:,:,i].mean()\n",
        "                canal_std = imagen[:,:,i].std()\n",
        "                stats_text += f\"{canales_nombres[i]}: μ={canal_mean:.3f}, σ={canal_std:.3f}\\n\"\n",
        "\n",
        "        # Mostrar texto con formato monoespaciado\n",
        "        plt.text(0.05, 0.95, stats_text, fontsize=10,\n",
        "                verticalalignment='top', fontfamily='monospace',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "    plt.suptitle('Dashboard de Análisis de Imagen', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"✓ Utilidades de visualización definidas y documentadas\")\n",
        "print(\"  → crear_grid_imagenes(): Grid organizado para múltiples imágenes\")\n",
        "print(\"  → mostrar_antes_despues(): Comparación lado a lado\")\n",
        "print(\"  → crear_dashboard_imagen(): Dashboard integral de análisis\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8-cVYqHelIC"
      },
      "source": [
        "## PLANTILLAS RÁPIDAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzVe9CcTelIC"
      },
      "source": [
        "# =============================================\n",
        "# PLANTILLAS RÁPIDAS PARA TAREAS COMUNES\n",
        "# =============================================\n",
        "\n",
        "def analisis_rapido_imagen(path_imagen):\n",
        "    \"\"\"\n",
        "    PLANTILLA 1: Análisis completo y rápido de una imagen individual.\n",
        "    Combina carga, análisis estadístico, visualización y conversión de espacios.\n",
        "\n",
        "    Args:\n",
        "        path_imagen (str): Ruta al archivo de imagen\n",
        "\n",
        "    Returns:\n",
        "        tuple: (imagen_cargada, dict_espacios_color) o None si hay error\n",
        "\n",
        "    Procesos incluidos:\n",
        "        - Carga segura con redimensionamiento estándar\n",
        "        - Análisis estadístico completo\n",
        "        - Dashboard visual integrado\n",
        "        - Conversión a múltiples espacios de color\n",
        "        - Visualización comparativa de espacios\n",
        "    \"\"\"\n",
        "    print(\"🚀 Iniciando análisis rápido de imagen...\")\n",
        "\n",
        "    # PASO 1: Cargar imagen con tamaño estándar para análisis\n",
        "    imagen = cargar_imagen_segura(path_imagen, target_size=(256, 256))\n",
        "    if imagen is None:\n",
        "        print(\"❌ Error: No se pudo cargar la imagen\")\n",
        "        return None\n",
        "\n",
        "    print(\"✓ Imagen cargada correctamente\")\n",
        "\n",
        "    # PASO 2: Análisis estadístico básico\n",
        "    print(\"\\n📊 Información estadística:\")\n",
        "    mostrar_imagen_info(imagen, \"Análisis Rápido\")\n",
        "\n",
        "    # PASO 3: Dashboard visual completo\n",
        "    print(\"\\n📈 Generando dashboard visual...\")\n",
        "    crear_dashboard_imagen(imagen)\n",
        "\n",
        "    # PASO 4: Conversión a múltiples espacios de color\n",
        "    print(\"\\n🎨 Convirtiendo espacios de color...\")\n",
        "    espacios = convertir_espacios_color(imagen)\n",
        "\n",
        "    # PASO 5: Visualización comparativa de espacios\n",
        "    imagenes_espacios = [espacios['rgb'], espacios['hsv'], espacios['gray']]\n",
        "    titulos_espacios = ['RGB (Original)', 'HSV (Tono-Saturación)', 'Escala de Grises']\n",
        "    crear_grid_imagenes(imagenes_espacios, titulos_espacios, filas=1)\n",
        "\n",
        "    print(\"✅ Análisis completado exitosamente\")\n",
        "    return imagen, espacios\n",
        "\n",
        "def pipeline_dataset_completo(carpeta_imagenes, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    PLANTILLA 2: Pipeline completo para procesamiento de dataset de imágenes.\n",
        "    Desde carga masiva hasta modelo entrenado y evaluado.\n",
        "\n",
        "    Args:\n",
        "        carpeta_imagenes (str): Ruta a carpeta con subcarpetas por categoría\n",
        "        target_size (tuple): Tamaño objetivo para todas las imágenes\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario completo con imágenes, características, datos ML y modelo\n",
        "\n",
        "    Estructura esperada de carpetas:\n",
        "        carpeta_imagenes/\n",
        "        ├── categoria1/\n",
        "        │   ├── imagen1.jpg\n",
        "        │   └── imagen2.jpg\n",
        "        └── categoria2/\n",
        "            ├── imagen3.jpg\n",
        "            └── imagen4.jpg\n",
        "    \"\"\"\n",
        "    print(\"🔄 Iniciando pipeline completo de dataset...\")\n",
        "\n",
        "    imagenes = []\n",
        "    etiquetas = []\n",
        "\n",
        "    # PASO 1: Carga masiva por categorías\n",
        "    print(\"📁 Cargando imágenes por categoría:\")\n",
        "    for categoria in os.listdir(carpeta_imagenes):\n",
        "        categoria_path = os.path.join(carpeta_imagenes, categoria)\n",
        "\n",
        "        # Verificar que sea directorio\n",
        "        if os.path.isdir(categoria_path):\n",
        "            print(f\"   🔍 Procesando categoría '{categoria}'...\")\n",
        "            contador_categoria = 0\n",
        "\n",
        "            # Procesar cada imagen en la categoría\n",
        "            for archivo in os.listdir(categoria_path):\n",
        "                # Verificar extensiones de imagen válidas\n",
        "                if archivo.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                    path_completo = os.path.join(categoria_path, archivo)\n",
        "                    img = cargar_imagen_segura(path_completo, target_size)\n",
        "\n",
        "                    if img is not None:\n",
        "                        imagenes.append(img)\n",
        "                        etiquetas.append(categoria)\n",
        "                        contador_categoria += 1\n",
        "\n",
        "            print(f\"      ✓ {contador_categoria} imágenes cargadas\")\n",
        "\n",
        "    total_imagenes = len(imagenes)\n",
        "    print(f\"\\n📊 Total: {total_imagenes} imágenes cargadas desde {len(set(etiquetas))} categorías\")\n",
        "\n",
        "    if total_imagenes == 0:\n",
        "        print(\"❌ Error: No se encontraron imágenes válidas\")\n",
        "        return None\n",
        "\n",
        "    # PASO 2: Conversión a arrays NumPy\n",
        "    X = np.array(imagenes)\n",
        "    y = np.array(etiquetas)\n",
        "\n",
        "    # PASO 3: Extracción masiva de características\n",
        "    print(f\"\\n🎯 Extrayendo características de {total_imagenes} imágenes...\")\n",
        "    features = []\n",
        "\n",
        "    # Barra de progreso simulada\n",
        "    for i, img in enumerate(imagenes):\n",
        "        feat = extraer_features_completas(img)\n",
        "        features.append(feat)\n",
        "\n",
        "        # Mostrar progreso cada 10%\n",
        "        if (i + 1) % max(1, total_imagenes // 10) == 0:\n",
        "            progreso = (i + 1) / total_imagenes * 100\n",
        "            print(f\"      📈 Progreso: {progreso:.0f}% ({i + 1}/{total_imagenes})\")\n",
        "\n",
        "    X_features = np.array(features)\n",
        "    print(f\"✓ Características extraídas: {X_features.shape[1]} features por imagen\")\n",
        "\n",
        "    # PASO 4: Preparación para ML\n",
        "    print(f\"\\n🤖 Preparando datos para Machine Learning...\")\n",
        "    datos_ml = preparar_datos_ml(X_features, y)\n",
        "\n",
        "    # PASO 5: Entrenamiento y evaluación rápida\n",
        "    print(f\"\\n🎲 Entrenamiento de modelo de validación...\")\n",
        "    modelo, pred_val, pred_test = entrenar_modelo_rapido(datos_ml)\n",
        "\n",
        "    # PASO 6: Compilar resultados\n",
        "    resultado = {\n",
        "        'imagenes_originales': X,           # Arrays de imágenes\n",
        "        'etiquetas': y,                     # Etiquetas de categorías\n",
        "        'caracteristicas': X_features,      # Features extraídos\n",
        "        'datos_ml': datos_ml,              # Conjuntos train/val/test preparados\n",
        "        'modelo': modelo,                   # Modelo entrenado\n",
        "        'predicciones_val': pred_val,      # Predicciones en validación\n",
        "        'predicciones_test': pred_test     # Predicciones en test\n",
        "    }\n",
        "\n",
        "    print(f\"\\n🎉 Pipeline completado exitosamente!\")\n",
        "    print(f\"   📝 Datos listos para análisis avanzado\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def segmentacion_rapida(imagen, metodo='kmeans', **kwargs):\n",
        "    \"\"\"\n",
        "    PLANTILLA 3: Segmentación rápida con múltiples algoritmos disponibles.\n",
        "    Permite experimentar fácilmente con diferentes técnicas de segmentación.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen a segmentar\n",
        "        metodo (str): Método de segmentación ('kmeans' o 'color_range')\n",
        "        **kwargs: Parámetros específicos del método\n",
        "\n",
        "    Returns:\n",
        "        tuple: (resultado_segmentacion, modelo_o_parametros)\n",
        "\n",
        "    Métodos disponibles:\n",
        "        - 'kmeans': Clustering automático en espacio HSV\n",
        "          Parámetros: n_clusters=5\n",
        "        - 'color_range': Segmentación por rango de color HSV\n",
        "          Parámetros: h_min=0.0, h_max=0.1, s_min=0.2, v_min=0.2\n",
        "    \"\"\"\n",
        "    print(f\"🎯 Iniciando segmentación usando método '{metodo}'...\")\n",
        "\n",
        "    if metodo == 'kmeans':\n",
        "        # SEGMENTACIÓN POR CLUSTERING\n",
        "        n_clusters = kwargs.get('n_clusters', 5)\n",
        "        print(f\"   🔬 Aplicando K-means con {n_clusters} clusters...\")\n",
        "\n",
        "        segmentacion, modelo = segmentar_por_color_hsv_auto(imagen, n_clusters)\n",
        "        parametros = {'metodo': 'kmeans', 'n_clusters': n_clusters}\n",
        "\n",
        "    elif metodo == 'color_range':\n",
        "        # SEGMENTACIÓN POR RANGO DE COLOR\n",
        "        h_min = kwargs.get('h_min', 0.0)\n",
        "        h_max = kwargs.get('h_max', 0.1)\n",
        "        s_min = kwargs.get('s_min', 0.2)\n",
        "        v_min = kwargs.get('v_min', 0.2)\n",
        "\n",
        "        print(f\"   🌈 Segmentando rango HSV: H[{h_min:.2f}-{h_max:.2f}], S≥{s_min:.2f}, V≥{v_min:.2f}\")\n",
        "\n",
        "        imagen_hsv = color.rgb2hsv(imagen)\n",
        "        segmentacion = crear_mascara_color_rango(imagen_hsv, h_min, h_max, s_min, v_min)\n",
        "\n",
        "        modelo = None\n",
        "        parametros = {\n",
        "            'metodo': 'color_range',\n",
        "            'h_min': h_min, 'h_max': h_max,\n",
        "            's_min': s_min, 'v_min': v_min\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ Error: Método '{metodo}' no reconocido\")\n",
        "        print(\"   💡 Métodos disponibles: 'kmeans', 'color_range'\")\n",
        "        return None, None\n",
        "\n",
        "    # Mostrar resultados comparativos\n",
        "    print(\"   📊 Generando visualización comparativa...\")\n",
        "    titulo_resultado = f\"Segmentación ({metodo.upper()})\"\n",
        "    mostrar_antes_despues(imagen, segmentacion, \"Original\", titulo_resultado)\n",
        "\n",
        "    # Estadísticas de la segmentación\n",
        "    if metodo == 'kmeans':\n",
        "        regiones_unicas = len(np.unique(segmentacion))\n",
        "        print(f\"   ✓ {regiones_unicas} regiones identificadas\")\n",
        "    else:\n",
        "        pixeles_segmentados = np.sum(segmentacion)\n",
        "        total_pixeles = segmentacion.size\n",
        "        porcentaje = (pixeles_segmentados / total_pixeles) * 100\n",
        "        print(f\"   ✓ {pixeles_segmentados} píxeles segmentados ({porcentaje:.1f}% del total)\")\n",
        "\n",
        "    print(\"🎯 Segmentación completada\")\n",
        "    return segmentacion, {'modelo': modelo, 'parametros': parametros}\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"✓ Plantillas rápidas definidas y documentadas\")\n",
        "print(\"\\n🚀 Plantillas disponibles:\")\n",
        "print(\"   1️⃣  analisis_rapido_imagen(path) - Análisis integral de imagen individual\")\n",
        "print(\"   2️⃣  pipeline_dataset_completo(carpeta) - Procesamiento completo de dataset\")\n",
        "print(\"   3️⃣  segmentacion_rapida(imagen, metodo, **params) - Segmentación experimental\")\n",
        "print(\"\\n💡 Cada plantilla incluye mensajes de progreso y manejo de errores\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eXNmoIelID"
      },
      "source": [
        "## EJEMPLOS DE USO\n",
        "\n",
        "### Ejemplo 1: Análisis rápido de imagen\n",
        "```python\n",
        "# Análisis completo con una sola función\n",
        "imagen, espacios = analisis_rapido_imagen('mi_imagen.jpg')\n",
        "\n",
        "# Acceder a diferentes espacios de color\n",
        "img_hsv = espacios['hsv']\n",
        "img_gray = espacios['gray']\n",
        "```\n",
        "\n",
        "### Ejemplo 2: Segmentación por color\n",
        "```python\n",
        "# Segmentación automática con K-means\n",
        "seg, info = segmentacion_rapida(imagen, 'kmeans', n_clusters=4)\n",
        "\n",
        "# Segmentación por rango de color específico (rojos)\n",
        "seg, info = segmentacion_rapida(imagen, 'color_range',\n",
        "                               h_min=0.9, h_max=1.0,\n",
        "                               s_min=0.5, v_min=0.3)\n",
        "```\n",
        "\n",
        "### Ejemplo 3: Pipeline completo de dataset\n",
        "```python\n",
        "# Procesamiento automático de dataset completo\n",
        "resultado = pipeline_dataset_completo('mi_dataset/')\n",
        "\n",
        "# Acceder a componentes individuales\n",
        "modelo = resultado['modelo']\n",
        "datos_ml = resultado['datos_ml']\n",
        "caracteristicas = resultado['caracteristicas']\n",
        "\n",
        "# Análisis avanzado\n",
        "mostrar_matriz_confusion(datos_ml['y_test'],\n",
        "                        resultado['predicciones_test'])\n",
        "```\n",
        "\n",
        "### Ejemplo 4: Extracción manual de características\n",
        "```python\n",
        "# Cargar y preparar imagen\n",
        "img = cargar_imagen_segura('imagen.jpg', target_size=(128, 128))\n",
        "\n",
        "# Extraer diferentes tipos de características\n",
        "features_completas = extraer_features_completas(img)  # 46 características\n",
        "features_color = extraer_features_color_completas(img)  # 15 características\n",
        "features_textura = extraer_features_textura_avanzadas(img)  # 7 características\n",
        "\n",
        "print(f\"Características extraídas: {len(features_completas)} total\")\n",
        "```\n",
        "\n",
        "### Ejemplo 5: Visualización avanzada\n",
        "```python\n",
        "# Grid de múltiples imágenes\n",
        "imagenes = [img1, img2, img3, img4]\n",
        "titulos = ['Original', 'Filtrada', 'Segmentada', 'Resultado']\n",
        "crear_grid_imagenes(imagenes, titulos, filas=2)\n",
        "\n",
        "# Dashboard completo\n",
        "crear_dashboard_imagen(imagen,\n",
        "                      mostrar_canales=True,\n",
        "                      mostrar_histograma=True,\n",
        "                      mostrar_estadisticas=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ¡Utilidades listas para usar!\n",
        "\n",
        "**🎯 Para usar en laboratorios:**\n",
        "1. Ejecuta la celda de **importaciones** al inicio\n",
        "2. Ejecuta las celdas de **utilidades** que necesites\n",
        "3. Usa las **plantillas rápidas** para tareas comunes\n",
        "4. Consulta el **glosario** para términos técnicos\n",
        "\n",
        "**💡 Consejos:**\n",
        "- Todas las funciones incluyen documentación detallada\n",
        "- Los mensajes de progreso te mantienen informado\n",
        "- Manejo robusto de errores en todas las operaciones\n",
        "- Parámetros por defecto optimizados para la mayoría de casos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671x6Ym5elID"
      },
      "source": [
        "---\n",
        "\n",
        "# GLOSARIO TÉCNICO\n",
        "\n",
        "## Términos de Procesamiento de Imágenes\n",
        "\n",
        "**Array/Arreglo**: Estructura de datos multidimensional de NumPy. Para imágenes RGB: shape (altura, ancho, 3)\n",
        "\n",
        "**BGR vs RGB**: Orden de canales de color. OpenCV usa BGR (Azul-Verde-Rojo), PIL/matplotlib usan RGB (Rojo-Verde-Azul)\n",
        "\n",
        "**Bounding Box**: Rectángulo mínimo que contiene completamente un objeto detectado\n",
        "\n",
        "**Canal**: Una de las componentes de color en una imagen (ej: R, G, B en RGB o H, S, V en HSV)\n",
        "\n",
        "**Clustering**: Técnica de agrupamiento que divide datos en grupos similares sin supervisión\n",
        "\n",
        "**Componentes Conectados**: Regiones de píxeles conectados que comparten características similares\n",
        "\n",
        "**Elemento Estructurante/Kernel**: Matriz pequeña usada en operaciones morfológicas (ej: círculo, cuadrado)\n",
        "\n",
        "**Escala de Grises**: Imagen con un solo canal representando intensidad de luminancia (0=negro, 1=blanco)\n",
        "\n",
        "**Espacio de Color**: Sistema de coordenadas para representar colores (RGB, HSV, LAB, etc.)\n",
        "\n",
        "**Máscara Binaria**: Imagen de 2 valores (0 y 1) que indica qué píxeles pertenecen a una región de interés\n",
        "\n",
        "**Normalización**: Proceso de escalar valores a un rango estándar (ej: [0,255] → [0,1])\n",
        "\n",
        "**Píxel**: Unidad mínima de una imagen digital. Contiene valores de intensidad para cada canal de color\n",
        "\n",
        "**Segmentación**: Proceso de dividir una imagen en regiones homogéneas o objetos de interés\n",
        "\n",
        "**Umbralización/Thresholding**: Técnica que convierte imagen en escala de grises a binaria usando un valor umbral\n",
        "\n",
        "## Espacios de Color\n",
        "\n",
        "**RGB (Red-Green-Blue)**:\n",
        "- R: Intensidad de rojo [0,1]\n",
        "- G: Intensidad de verde [0,1]  \n",
        "- B: Intensidad de azul [0,1]\n",
        "- Aditivo (suma colores para crear blanco)\n",
        "\n",
        "**HSV (Hue-Saturation-Value)**:\n",
        "- H: Tono/Matiz [0,1] (tipo de color: rojo≈0, verde≈0.33, azul≈0.67)\n",
        "- S: Saturación [0,1] (pureza del color: 0=gris, 1=color puro)\n",
        "- V: Valor/Brillo [0,1] (intensidad luminosa: 0=negro, 1=brillante)\n",
        "\n",
        "**LAB (L*a*b*)**:\n",
        "- L: Luminancia [0,100] (brillo perceptual)\n",
        "- a: Verde (-) a Magenta (+)\n",
        "- b: Azul (-) a Amarillo (+)\n",
        "- Perceptualmente uniforme (diferencias numéricas = diferencias visuales)\n",
        "\n",
        "## Operaciones Morfológicas\n",
        "\n",
        "**Erosión**: Reduce el tamaño de regiones blancas (adelgaza objetos)\n",
        "\n",
        "**Dilatación**: Expande el tamaño de regiones blancas (engrosa objetos)\n",
        "\n",
        "**Apertura (Opening)**: Erosión seguida de dilatación (elimina ruido pequeño)\n",
        "\n",
        "**Cierre (Closing)**: Dilatación seguida de erosión (cierra huecos pequeños)\n",
        "\n",
        "## Filtros y Detección de Bordes\n",
        "\n",
        "**Filtro Sobel**: Detecta gradientes (cambios de intensidad) en direcciones horizontal y vertical\n",
        "\n",
        "**Detector Canny**: Algoritmo avanzado de detección de bordes con supresión de no-máximos\n",
        "\n",
        "**Gradiente**: Medida del cambio de intensidad entre píxeles vecinos\n",
        "\n",
        "## Características (Features) para ML\n",
        "\n",
        "**Estadísticas de Primer Orden**: Media, desviación estándar, mediana (distribución de intensidades)\n",
        "\n",
        "**Estadísticas de Segundo Orden**: Correlación, contraste, homogeneidad (relaciones espaciales)\n",
        "\n",
        "**Histograma**: Distribución de frecuencias de intensidades de píxeles\n",
        "\n",
        "**Textura**: Patrones espaciales de variación de intensidad (rugosidad, suavidad, regularidad)\n",
        "\n",
        "## Machine Learning\n",
        "\n",
        "**Conjunto de Entrenamiento (Train)**: Datos usados para enseñar al modelo (≈60%)\n",
        "\n",
        "**Conjunto de Validación (Val)**: Datos para ajustar hiperparámetros y evitar overfitting (≈20%)\n",
        "\n",
        "**Conjunto de Prueba (Test)**: Datos para evaluación final del modelo (≈20%)\n",
        "\n",
        "**Características/Features**: Variables numéricas que describen cada muestra (ej: color promedio, textura)\n",
        "\n",
        "**Etiquetas/Labels**: Categorías o valores objetivo que el modelo debe predecir\n",
        "\n",
        "**Matriz de Confusión**: Tabla que muestra aciertos y errores de clasificación por cada clase\n",
        "\n",
        "**Overfitting**: Modelo que memoriza datos de entrenamiento pero no generaliza a datos nuevos\n",
        "\n",
        "**RandomForest**: Algoritmo que combina múltiples árboles de decisión para mayor robustez\n",
        "\n",
        "**Validación Estratificada**: División que mantiene la proporción de cada clase en todos los conjuntos\n",
        "\n",
        "## Métricas de Evaluación\n",
        "\n",
        "**Accuracy (Exactitud)**: Proporción de predicciones correctas sobre el total\n",
        "\n",
        "**Precisión**: De las predicciones positivas, cuántas fueron correctas\n",
        "\n",
        "**Recall (Sensibilidad)**: De los casos positivos reales, cuántos fueron detectados\n",
        "\n",
        "**F1-Score**: Media armónica entre precisión y recall\n",
        "\n",
        "## Bibliotecas Python\n",
        "\n",
        "**NumPy**: Operaciones numéricas y arrays multidimensionales eficientes\n",
        "\n",
        "**PIL (Pillow)**: Carga, manipulación y guardado de imágenes en múltiples formatos\n",
        "\n",
        "**OpenCV (cv2)**: Biblioteca completa de computer vision (¡usa formato BGR!)\n",
        "\n",
        "**scikit-image**: Algoritmos especializados de procesamiento de imágenes\n",
        "\n",
        "**scikit-learn**: Herramientas de machine learning y análisis de datos\n",
        "\n",
        "**matplotlib**: Creación de gráficos y visualización de imágenes\n",
        "\n",
        "**seaborn**: Visualizaciones estadísticas avanzadas basadas en matplotlib\n",
        "\n",
        "---\n",
        "\n",
        "## Referencias Rápidas de Rangos\n",
        "\n",
        "### Rangos de Tono (H) en HSV para Colores Comunes:\n",
        "- **Rojo**: 0.0-0.1 y 0.9-1.0 (está en ambos extremos)\n",
        "- **Naranja**: 0.05-0.15\n",
        "- **Amarillo**: 0.15-0.25  \n",
        "- **Verde**: 0.25-0.45\n",
        "- **Cian**: 0.45-0.55\n",
        "- **Azul**: 0.55-0.75\n",
        "- **Magenta**: 0.75-0.9\n",
        "\n",
        "### Valores Típicos de Saturación (S) y Valor (V):\n",
        "- **Colores vivos**: S > 0.5, V > 0.5\n",
        "- **Colores pasteles**: S < 0.5, V > 0.7\n",
        "- **Colores oscuros**: V < 0.3 (independiente de S)\n",
        "- **Grises**: S < 0.2 (independiente de V)\n",
        "\n",
        "### Tamaños de Kernel Recomendados:\n",
        "- **Ruido pequeño**: kernel = 2-3 píxeles\n",
        "- **Detalles medianos**: kernel = 5-7 píxeles  \n",
        "- **Objetos grandes**: kernel = 10+ píxeles\n",
        "\n",
        "---\n",
        "\n",
        "## ¡Todo listo para el laboratorio integrador!\n",
        "\n",
        "Este cuaderno te proporciona todas las herramientas necesarias para trabajar eficientemente en el procesamiento de imágenes y machine learning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}