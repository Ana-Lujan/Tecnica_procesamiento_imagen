{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCzuM5KzelH6"
      },
      "source": [
        "# UTILIDADES Y PLANTILLAS - LABORATORIO INTEGRADOR\n",
        "\n",
        "## Contenido\n",
        "Este cuaderno contiene **funciones de utilidad** y **plantillas de c√≥digo** para usar en los laboratorios integradores.\n",
        "\n",
        "### Prop√≥sito:\n",
        "- **Acelerar el desarrollo** en los laboratorios\n",
        "- **Evitar repetir c√≥digo** com√∫n\n",
        "- **Proporcionar ejemplos** de buenas pr√°cticas\n",
        "- **Facilitar la experimentaci√≥n** r√°pida\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvp_c95NelH8"
      },
      "source": [
        "## IMPORTACIONES EST√ÅNDAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwkKRivKelH8"
      },
      "source": [
        "# ============================================\n",
        "# IMPORTACIONES EST√ÅNDAR - COPIAR Y PEGAR\n",
        "# ============================================\n",
        "# Copiar y pegar este bloque en cualquier laboratorio\n",
        "\n",
        "# Procesamiento num√©rico y manipulaci√≥n de datos\n",
        "import numpy as np          # Operaciones num√©ricas y arrays multidimensionales\n",
        "import pandas as pd         # An√°lisis y manipulaci√≥n de datos estructurados\n",
        "\n",
        "# Bibliotecas de visualizaci√≥n\n",
        "import matplotlib.pyplot as plt    # Gr√°ficos y visualizaciones b√°sicas\n",
        "import seaborn as sns             # Visualizaciones estad√≠sticas avanzadas\n",
        "\n",
        "# Procesamiento de im√°genes - Bibliotecas principales\n",
        "from PIL import Image, ImageEnhance           # Python Imaging Library - carga y manipulaci√≥n b√°sica\n",
        "import cv2                                    # OpenCV - procesamiento avanzado (nota: usa BGR)\n",
        "from skimage import color, feature, measure, filters, morphology, segmentation  # Scikit-image - algoritmos especializados\n",
        "\n",
        "# Machine Learning y an√°lisis predictivo\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder    # Preprocesamiento de datos\n",
        "from sklearn.model_selection import train_test_split             # Divisi√≥n de datasets\n",
        "from sklearn.ensemble import RandomForestClassifier              # Algoritmo de clasificaci√≥n\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # M√©tricas de evaluaci√≥n\n",
        "\n",
        "# Utilidades del sistema operativo\n",
        "import os        # Navegaci√≥n de archivos y carpetas\n",
        "import glob      # B√∫squeda de archivos con patrones\n",
        "import warnings  # Control de mensajes de advertencia\n",
        "warnings.filterwarnings('ignore')  # Suprimir advertencias para salida m√°s limpia\n",
        "\n",
        "# Espec√≠fico para Google Colab\n",
        "from google.colab import files    # Subida y descarga de archivos en Colab\n",
        "\n",
        "# Configuraci√≥n global de matplotlib para gr√°ficos m√°s grandes y legibles\n",
        "plt.rcParams['figure.figsize'] = (12, 8)    # Tama√±o por defecto de las figuras\n",
        "plt.rcParams['font.size'] = 10              # Tama√±o de fuente por defecto\n",
        "\n",
        "# Semilla para reproducibilidad de resultados aleatorios\n",
        "np.random.seed(42)  # Garantiza que los resultados aleatorios sean consistentes\n",
        "\n",
        "print(\"‚úì Importaciones cargadas correctamente\")\n",
        "print(\"‚úì Configuraci√≥n aplicada\")\n",
        "print(\"‚úì Listo para comenzar el an√°lisis\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16CBdmlOelH9"
      },
      "source": [
        "## UTILIDADES DE IM√ÅGENES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USj824w0elH-"
      },
      "source": [
        "# =============================================\n",
        "# UTILIDADES PARA MANEJO SEGURO DE IM√ÅGENES\n",
        "# =============================================\n",
        "\n",
        "def cargar_imagen_segura(path, target_size=None):\n",
        "    \"\"\"\n",
        "    Carga una imagen de forma segura con manejo completo de errores.\n",
        "    Convierte autom√°ticamente a RGB y normaliza valores entre 0-1.\n",
        "\n",
        "    Args:\n",
        "        path (str): Ruta completa al archivo de imagen\n",
        "        target_size (tuple): Tupla (ancho, alto) para redimensionar la imagen\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Array normalizado (0-1) o None si hay error\n",
        "\n",
        "    Ejemplo:\n",
        "        img = cargar_imagen_segura('foto.jpg', target_size=(256, 256))\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Abrir imagen usando PIL (soporta m√∫ltiples formatos)\n",
        "        img = Image.open(path)\n",
        "\n",
        "        # Convertir a RGB si est√° en otro modo (RGBA, L, etc.)\n",
        "        # Esto garantiza consistencia en el n√∫mero de canales\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        # Redimensionar si se especifica un tama√±o objetivo\n",
        "        # LANCZOS ofrece mejor calidad para redimensionamiento\n",
        "        if target_size:\n",
        "            img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        # Convertir a numpy array y normalizar a rango [0,1]\n",
        "        # Divisi√≥n por 255 convierte de uint8 [0,255] a float [0,1]\n",
        "        return np.array(img) / 255.0\n",
        "\n",
        "    except Exception as e:\n",
        "        # Capturar cualquier error (archivo no encontrado, formato no v√°lido, etc.)\n",
        "        print(f\"Error cargando {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def mostrar_imagen_info(imagen, titulo=\"Imagen\"):\n",
        "    \"\"\"\n",
        "    Muestra informaci√≥n estad√≠stica completa de una imagen.\n",
        "    √ötil para debugging y an√°lisis exploratorio.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Array de la imagen\n",
        "        titulo (str): T√≠tulo descriptivo para la salida\n",
        "\n",
        "    Ejemplo:\n",
        "        mostrar_imagen_info(mi_imagen, \"Imagen Original\")\n",
        "    \"\"\"\n",
        "    print(f\"{titulo.upper()}:\")\n",
        "    print(f\"   Shape: {imagen.shape}\")                    # Dimensiones (altura, ancho, canales)\n",
        "    print(f\"   Tipo de datos: {imagen.dtype}\")           # Tipo de datos (float64, uint8, etc.)\n",
        "    print(f\"   Rango de valores: [{imagen.min():.3f}, {imagen.max():.3f}]\")  # Min y max\n",
        "    print(f\"   Valor promedio: {imagen.mean():.3f}\")     # Media de todos los p√≠xeles\n",
        "    print(f\"   Desviaci√≥n est√°ndar: {imagen.std():.3f}\") # Variabilidad de los valores\n",
        "\n",
        "def visualizar_canales_rgb(imagen, titulo=\"An√°lisis de Canales RGB\"):\n",
        "    \"\"\"\n",
        "    Visualiza los canales RGB de una imagen por separado.\n",
        "    √ötil para entender la contribuci√≥n de cada color primario.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB a analizar\n",
        "        titulo (str): T√≠tulo para la visualizaci√≥n\n",
        "\n",
        "    Nota:\n",
        "        Cada canal se muestra con su colormap correspondiente para mejor interpretaci√≥n.\n",
        "    \"\"\"\n",
        "    # Crear subplot con 4 columnas: original + 3 canales\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "    # Mostrar imagen original en color completo\n",
        "    axes[0].imshow(imagen)\n",
        "    axes[0].set_title('Imagen Completa (RGB)')\n",
        "    axes[0].axis('off')  # Ocultar ejes para mejor visualizaci√≥n\n",
        "\n",
        "    # Definir nombres y mapas de color para cada canal\n",
        "    canales = ['Rojo (R)', 'Verde (G)', 'Azul (B)']\n",
        "    colormaps = ['Reds', 'Greens', 'Blues']  # Mapas de color tem√°ticos\n",
        "\n",
        "    # Mostrar cada canal individual\n",
        "    for i in range(3):\n",
        "        # Extraer canal espec√≠fico ([:,:,i] selecciona el canal i)\n",
        "        axes[i+1].imshow(imagen[:,:,i], cmap=colormaps[i])\n",
        "        axes[i+1].set_title(f'Canal {canales[i]}')\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "    # Configurar layout y mostrar\n",
        "    plt.suptitle(titulo)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def convertir_espacios_color(imagen):\n",
        "    \"\"\"\n",
        "    Convierte una imagen RGB a m√∫ltiples espacios de color.\n",
        "    √ötil para an√°lisis comparativo y selecci√≥n del espacio √≥ptimo.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con diferentes representaciones de la imagen\n",
        "\n",
        "    Espacios incluidos:\n",
        "        - RGB: Red, Green, Blue (original)\n",
        "        - HSV: Hue (tono), Saturation (saturaci√≥n), Value (valor)\n",
        "        - Grayscale: Escala de grises (luminancia)\n",
        "        - LAB: L*a*b* (perceptualmente uniforme)\n",
        "    \"\"\"\n",
        "    espacios = {\n",
        "        'rgb': imagen,                      # Espacio original\n",
        "        'hsv': color.rgb2hsv(imagen),       # Separaci√≥n tono/saturaci√≥n/brillo\n",
        "        'gray': color.rgb2gray(imagen),     # Informaci√≥n de luminancia √∫nicamente\n",
        "        'lab': color.rgb2lab(imagen)        # Espacio perceptualmente uniforme\n",
        "    }\n",
        "\n",
        "    return espacios\n",
        "\n",
        "# Mensaje de confirmaci√≥n para el usuario\n",
        "print(\"‚úì Utilidades de im√°genes definidas y documentadas\")\n",
        "print(\"  ‚Üí cargar_imagen_segura(): Carga robusta con manejo de errores\")\n",
        "print(\"  ‚Üí mostrar_imagen_info(): Estad√≠sticas detalladas de la imagen\")\n",
        "print(\"  ‚Üí visualizar_canales_rgb(): Separaci√≥n visual de canales\")\n",
        "print(\"  ‚Üí convertir_espacios_color(): M√∫ltiples representaciones\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY9y9OwjelH_"
      },
      "source": [
        "## UTILIDADES DE SEGMENTACI√ìN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAfLFCJwelH_"
      },
      "source": [
        "# =========================================================\n",
        "# UTILIDADES AVANZADAS DE SEGMENTACI√ìN DE IM√ÅGENES\n",
        "# =========================================================\n",
        "\n",
        "def segmentar_por_color_hsv_auto(imagen, num_colores=5):\n",
        "    \"\"\"\n",
        "    Segmentaci√≥n autom√°tica usando clustering K-means en espacio HSV.\n",
        "    Agrupa p√≠xeles similares por sus caracter√≠sticas de tono y saturaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "        num_colores (int): N√∫mero de clusters (regiones) deseadas\n",
        "\n",
        "    Returns:\n",
        "        tuple: (m√°scara_segmentada, modelo_kmeans)\n",
        "        - m√°scara_segmentada: Array 2D con etiquetas de cluster por p√≠xel\n",
        "        - modelo_kmeans: Objeto KMeans entrenado para reutilizaci√≥n\n",
        "\n",
        "    Ventaja del HSV: Separaci√≥n natural entre tono (color) y brillo\n",
        "    \"\"\"\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # Convertir RGB a HSV para mejor separaci√≥n de colores\n",
        "    # HSV separa informaci√≥n crom√°tica (H,S) de luminancia (V)\n",
        "    imagen_hsv = color.rgb2hsv(imagen)\n",
        "\n",
        "    # Obtener dimensiones para reshape posterior\n",
        "    altura, ancho, _ = imagen_hsv.shape\n",
        "\n",
        "    # Usar solo canales H (tono) y S (saturaci√≥n) para clustering\n",
        "    # El canal V (valor/brillo) puede variar por iluminaci√≥n\n",
        "    pixeles_hs = imagen_hsv[:,:,:2].reshape(-1, 2)  # Reshape a (n_pixeles, 2)\n",
        "\n",
        "    # Aplicar K-means clustering\n",
        "    # random_state=42 garantiza resultados reproducibles\n",
        "    kmeans = KMeans(n_clusters=num_colores, random_state=42)\n",
        "    etiquetas = kmeans.fit_predict(pixeles_hs)\n",
        "\n",
        "    # Reformar etiquetas de vuelta a forma de imagen\n",
        "    segmentacion = etiquetas.reshape(altura, ancho)\n",
        "\n",
        "    return segmentacion, kmeans\n",
        "\n",
        "def crear_mascara_color_rango(imagen_hsv, h_min, h_max, s_min=0.2, v_min=0.2):\n",
        "    \"\"\"\n",
        "    Crea m√°scara binaria para segmentar un rango espec√≠fico de colores.\n",
        "    √ötil para detectar objetos de colores conocidos (ej: frutas, se√±ales).\n",
        "\n",
        "    Args:\n",
        "        imagen_hsv (numpy.ndarray): Imagen en espacio HSV [0,1]\n",
        "        h_min, h_max (float): Rango de tono (Hue) [0,1]\n",
        "        s_min (float): Saturaci√≥n m√≠nima (evita colores desaturados)\n",
        "        v_min (float): Valor m√≠nimo (evita p√≠xeles muy oscuros)\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: M√°scara binaria (1 donde cumple condiciones, 0 donde no)\n",
        "\n",
        "    Ejemplo rangos de tono:\n",
        "        - Rojo: 0.0-0.1 y 0.9-1.0 (el rojo est√° en los extremos)\n",
        "        - Verde: 0.2-0.4\n",
        "        - Azul: 0.5-0.7\n",
        "    \"\"\"\n",
        "    # Crear m√°scaras individuales para cada condici√≥n\n",
        "    mask_h = (imagen_hsv[:,:,0] >= h_min) & (imagen_hsv[:,:,0] <= h_max)  # Rango de tono\n",
        "    mask_s = imagen_hsv[:,:,1] >= s_min  # Saturaci√≥n m√≠nima (evita grises)\n",
        "    mask_v = imagen_hsv[:,:,2] >= v_min  # Valor m√≠nimo (evita negro/sombras)\n",
        "\n",
        "    # Combinar todas las condiciones con operador AND l√≥gico\n",
        "    # Un p√≠xel debe cumplir TODAS las condiciones para ser incluido\n",
        "    mask_final = mask_h & mask_s & mask_v\n",
        "\n",
        "    # Convertir boolean a uint8 para compatibilidad con OpenCV\n",
        "    return mask_final.astype(np.uint8)\n",
        "\n",
        "def limpiar_mascara_morfologia(mascara, tam_kernel=3, operaciones=['close', 'open']):\n",
        "    \"\"\"\n",
        "    Limpia m√°scaras binarias usando operaciones morfol√≥gicas.\n",
        "    Elimina ruido y conecta regiones fragmentadas.\n",
        "\n",
        "    Args:\n",
        "        mascara (numpy.ndarray): M√°scara binaria a limpiar\n",
        "        tam_kernel (int): Tama√±o del elemento estructurante (kernel)\n",
        "        operaciones (list): Lista de operaciones a aplicar en orden\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: M√°scara limpiada\n",
        "\n",
        "    Operaciones disponibles:\n",
        "        - 'close': Cierra huecos peque√±os (dilataci√≥n + erosi√≥n)\n",
        "        - 'open': Elimina ruido peque√±o (erosi√≥n + dilataci√≥n)\n",
        "        - 'erode': Reduce el tama√±o de las regiones\n",
        "        - 'dilate': Expande las regiones\n",
        "    \"\"\"\n",
        "    from skimage.morphology import disk, closing, opening, erosion, dilation\n",
        "\n",
        "    # Crear elemento estructurante circular\n",
        "    # disk() crea un c√≠rculo que preserva mejor las formas naturales\n",
        "    kernel = disk(tam_kernel)\n",
        "    resultado = mascara.copy()\n",
        "\n",
        "    # Aplicar operaciones en el orden especificado\n",
        "    for op in operaciones:\n",
        "        if op == 'close':\n",
        "            # Closing: Conecta regiones cercanas y cierra huecos\n",
        "            resultado = closing(resultado, kernel)\n",
        "        elif op == 'open':\n",
        "            # Opening: Elimina regiones peque√±as (ruido)\n",
        "            resultado = opening(resultado, kernel)\n",
        "        elif op == 'erode':\n",
        "            # Erosi√≥n: Reduce tama√±o de regiones (adelgaza bordes)\n",
        "            resultado = erosion(resultado, kernel)\n",
        "        elif op == 'dilate':\n",
        "            # Dilataci√≥n: Expande regiones (engrosa bordes)\n",
        "            resultado = dilation(resultado, kernel)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def analizar_regiones_conectadas(mascara_binaria, min_area=50):\n",
        "    \"\"\"\n",
        "    Identifica y analiza objetos individuales en una m√°scara binaria.\n",
        "    Extrae propiedades geom√©tricas de cada regi√≥n conectada.\n",
        "\n",
        "    Args:\n",
        "        mascara_binaria (numpy.ndarray): M√°scara binaria con objetos\n",
        "        min_area (int): √Årea m√≠nima en p√≠xeles para considerar un objeto\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de objetos regionprops con propiedades geom√©tricas\n",
        "\n",
        "    Propiedades √∫tiles de cada regi√≥n:\n",
        "        - .area: √Årea en p√≠xeles\n",
        "        - .bbox: Bounding box (min_row, min_col, max_row, max_col)\n",
        "        - .centroid: Centro de masa\n",
        "        - .eccentricity: Excentricidad (0=c√≠rculo, 1=l√≠nea)\n",
        "        - .perimeter: Per√≠metro\n",
        "    \"\"\"\n",
        "    # Etiquetar regiones conectadas (componentes conectados)\n",
        "    # Cada objeto recibe una etiqueta num√©rica √∫nica\n",
        "    etiquetas = measure.label(mascara_binaria)\n",
        "\n",
        "    # Extraer propiedades geom√©tricas de cada regi√≥n\n",
        "    # regionprops calcula m√∫ltiples caracter√≠sticas autom√°ticamente\n",
        "    regiones = measure.regionprops(etiquetas)\n",
        "\n",
        "    # Filtrar regiones muy peque√±as (probablemente ruido)\n",
        "    regiones_filtradas = [r for r in regiones if r.area >= min_area]\n",
        "\n",
        "    return regiones_filtradas\n",
        "\n",
        "def dibujar_bounding_boxes(ax, regiones, color='red', alpha=0.8):\n",
        "    \"\"\"\n",
        "    Dibuja rect√°ngulos delimitadores (bounding boxes) alrededor de objetos detectados.\n",
        "    √ötil para visualizar resultados de detecci√≥n de objetos.\n",
        "\n",
        "    Args:\n",
        "        ax (matplotlib.axes): Eje donde dibujar los rect√°ngulos\n",
        "        regiones (list): Lista de objetos regionprops\n",
        "        color (str): Color de los rect√°ngulos\n",
        "        alpha (float): Transparencia (0=transparente, 1=opaco)\n",
        "\n",
        "    Nota: Debe llamarse despu√©s de ax.imshow() y antes de plt.show()\n",
        "    \"\"\"\n",
        "    import matplotlib.patches as patches\n",
        "\n",
        "    # Iterar sobre cada regi√≥n detectada\n",
        "    for region in regiones:\n",
        "        # Obtener bounding box: (min_row, min_col, max_row, max_col)\n",
        "        bbox = region.bbox\n",
        "\n",
        "        # Crear rect√°ngulo para matplotlib\n",
        "        # Nota: matplotlib usa (x,y) = (col,row), por eso se invierten las coordenadas\n",
        "        rect = patches.Rectangle(\n",
        "            (bbox[1], bbox[0]),           # Esquina inferior izquierda (x,y)\n",
        "            bbox[3] - bbox[1],            # Ancho (max_col - min_col)\n",
        "            bbox[2] - bbox[0],            # Alto (max_row - min_row)\n",
        "            linewidth=2,                  # Grosor del borde\n",
        "            edgecolor=color,              # Color del borde\n",
        "            facecolor='none',             # Sin relleno (solo borde)\n",
        "            alpha=alpha                   # Transparencia\n",
        "        )\n",
        "\n",
        "        # Agregar rect√°ngulo al eje\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"‚úì Utilidades de segmentaci√≥n definidas y documentadas\")\n",
        "print(\"  ‚Üí segmentar_por_color_hsv_auto(): Clustering autom√°tico en HSV\")\n",
        "print(\"  ‚Üí crear_mascara_color_rango(): Segmentaci√≥n por rango de color\")\n",
        "print(\"  ‚Üí limpiar_mascara_morfologia(): Limpieza morfol√≥gica de m√°scaras\")\n",
        "print(\"  ‚Üí analizar_regiones_conectadas(): Detecci√≥n de objetos individuales\")\n",
        "print(\"  ‚Üí dibujar_bounding_boxes(): Visualizaci√≥n de detecciones\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0igfUAqelIA"
      },
      "source": [
        "## UTILIDADES DE EXTRACCI√ìN DE CARACTER√çSTICAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtbH3zToelIA"
      },
      "source": [
        "# ==============================================================\n",
        "# EXTRACCI√ìN AVANZADA DE CARACTER√çSTICAS PARA MACHINE LEARNING\n",
        "# ==============================================================\n",
        "\n",
        "def extraer_estadisticas_basicas(imagen_canal):\n",
        "    \"\"\"\n",
        "    Extrae estad√≠sticas descriptivas fundamentales de un canal de imagen.\n",
        "    Estas m√©tricas capturan la distribuci√≥n de intensidades en la imagen.\n",
        "\n",
        "    Args:\n",
        "        imagen_canal (numpy.ndarray): Canal individual de imagen (2D array)\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con estad√≠sticas b√°sicas\n",
        "\n",
        "    Estad√≠sticas calculadas:\n",
        "        - Media: Intensidad promedio (indica brillo general)\n",
        "        - Desviaci√≥n est√°ndar: Variabilidad de intensidades (indica contraste)\n",
        "        - Mediana: Valor central (robusto a valores at√≠picos)\n",
        "        - Cuartiles: Q25 y Q75 (rango intercuart√≠lico)\n",
        "        - M√≠nimo/M√°ximo: Rango completo de valores\n",
        "    \"\"\"\n",
        "    # Aplanar imagen a vector 1D para c√°lculos estad√≠sticos\n",
        "    datos = imagen_canal.flatten()\n",
        "\n",
        "    # Calcular estad√≠sticas descriptivas\n",
        "    estadisticas = {\n",
        "        'media': np.mean(datos),              # Promedio aritm√©tico\n",
        "        'std': np.std(datos),                 # Desviaci√≥n est√°ndar (medida de dispersi√≥n)\n",
        "        'mediana': np.median(datos),          # Valor del percentil 50\n",
        "        'q25': np.percentile(datos, 25),      # Primer cuartil\n",
        "        'q75': np.percentile(datos, 75),      # Tercer cuartil\n",
        "        'min': np.min(datos),                 # Valor m√≠nimo\n",
        "        'max': np.max(datos)                  # Valor m√°ximo\n",
        "    }\n",
        "\n",
        "    return estadisticas\n",
        "\n",
        "def extraer_features_color_completas(imagen):\n",
        "    \"\"\"\n",
        "    Extrae caracter√≠sticas completas de color en espacios RGB y HSV.\n",
        "    Combina informaci√≥n crom√°tica de ambos espacios para mayor robustez.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector de caracter√≠sticas de color (15 elementos)\n",
        "\n",
        "    Caracter√≠sticas extra√≠das:\n",
        "        RGB: 9 features (media, std, mediana por canal R, G, B)\n",
        "        HSV: 6 features (media, std por canal H, S, V)\n",
        "        Total: 15 caracter√≠sticas de color\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # CARACTER√çSTICAS RGB (3 canales √ó 3 estad√≠sticas = 9 features)\n",
        "    for canal in range(3):\n",
        "        stats = extraer_estadisticas_basicas(imagen[:,:,canal])\n",
        "        # Seleccionar las 3 estad√≠sticas m√°s informativas por canal\n",
        "        features.extend([stats['media'], stats['std'], stats['mediana']])\n",
        "\n",
        "    # CARACTER√çSTICAS HSV (separaci√≥n crom√°tica/luminancia)\n",
        "    imagen_hsv = color.rgb2hsv(imagen)\n",
        "    for canal in range(3):\n",
        "        stats = extraer_estadisticas_basicas(imagen_hsv[:,:,canal])\n",
        "        # HSV: solo media y std son m√°s relevantes (mediana menos informativa)\n",
        "        features.extend([stats['media'], stats['std']])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extraer_features_textura_avanzadas(imagen):\n",
        "    \"\"\"\n",
        "    Extrae caracter√≠sticas avanzadas de textura usando filtros de gradiente.\n",
        "    Captura informaci√≥n sobre patrones, bordes y rugosidad de la superficie.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB o escala de grises\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector de caracter√≠sticas de textura (7 elementos)\n",
        "\n",
        "    T√©cnicas utilizadas:\n",
        "        - Filtros de Sobel: Detectan gradientes horizontales y verticales\n",
        "        - Detector de Canny: Identifica bordes bien definidos\n",
        "        - Estad√≠sticas de intensidad: Propiedades b√°sicas de luminancia\n",
        "    \"\"\"\n",
        "    # Convertir a escala de grises si es necesario (textura no necesita color)\n",
        "    if len(imagen.shape) == 3:\n",
        "        imagen_gray = color.rgb2gray(imagen)\n",
        "    else:\n",
        "        imagen_gray = imagen\n",
        "\n",
        "    features = []\n",
        "\n",
        "    # FILTROS DE SOBEL para detecci√≥n de gradientes\n",
        "    # Sobel horizontal: detecta cambios verticales (l√≠neas horizontales)\n",
        "    sobel_h = filters.sobel_h(imagen_gray)\n",
        "    # Sobel vertical: detecta cambios horizontales (l√≠neas verticales)\n",
        "    sobel_v = filters.sobel_v(imagen_gray)\n",
        "\n",
        "    # Estad√≠sticas de gradientes (intensidad y variabilidad de bordes)\n",
        "    features.extend([\n",
        "        np.mean(np.abs(sobel_h)),    # Intensidad promedio de gradiente horizontal\n",
        "        np.mean(np.abs(sobel_v)),    # Intensidad promedio de gradiente vertical\n",
        "        np.std(sobel_h),             # Variabilidad de gradiente horizontal\n",
        "        np.std(sobel_v)              # Variabilidad de gradiente vertical\n",
        "    ])\n",
        "\n",
        "    # DETECTOR DE CANNY para bordes bien definidos\n",
        "    # Canny es m√°s selectivo que Sobel (menos ruido, bordes m√°s limpios)\n",
        "    bordes = feature.canny(imagen_gray)\n",
        "    # Densidad de bordes: proporci√≥n de p√≠xeles que son borde\n",
        "    features.append(np.sum(bordes) / bordes.size)\n",
        "\n",
        "    # CARACTER√çSTICAS DE INTENSIDAD b√°sicas\n",
        "    features.extend([\n",
        "        np.mean(imagen_gray),        # Brillo promedio\n",
        "        np.std(imagen_gray)          # Contraste general\n",
        "    ])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def calcular_histograma_color(imagen, bins=32):\n",
        "    \"\"\"\n",
        "    Calcula histograma concatenado de los 3 canales RGB.\n",
        "    Los histogramas capturan la distribuci√≥n de colores en la imagen.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB [0,1]\n",
        "        bins (int): N√∫mero de bins por canal (resoluci√≥n del histograma)\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Histograma concatenado normalizado (bins√ó3 elementos)\n",
        "\n",
        "    Normalizaci√≥n: Cada histograma suma 1.0 (distribuci√≥n de probabilidad)\n",
        "    Ventaja: Invariante al tama√±o de la imagen\n",
        "    \"\"\"\n",
        "    histograma = []\n",
        "\n",
        "    # Procesar cada canal RGB por separado\n",
        "    for canal in range(3):\n",
        "        # Calcular histograma en el rango [0,1] (im√°genes normalizadas)\n",
        "        hist, _ = np.histogram(imagen[:,:,canal], bins=bins, range=(0, 1))\n",
        "\n",
        "        # Normalizar para que sume 1 (convertir a probabilidades)\n",
        "        hist = hist / np.sum(hist)\n",
        "        histograma.extend(hist)\n",
        "\n",
        "    return np.array(histograma)\n",
        "\n",
        "def extraer_features_completas(imagen):\n",
        "    \"\"\"\n",
        "    Combina TODAS las caracter√≠sticas disponibles en un vector √∫nico.\n",
        "    Esta funci√≥n integra color, textura e histograma para m√°xima informaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB normalizada [0,1]\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Vector completo de caracter√≠sticas\n",
        "\n",
        "    Composici√≥n del vector:\n",
        "        - Caracter√≠sticas de color: 15 elementos (RGB + HSV)\n",
        "        - Caracter√≠sticas de textura: 7 elementos (gradientes + bordes)\n",
        "        - Histograma reducido: 24 elementos (8 bins √ó 3 canales)\n",
        "        Total: 46 caracter√≠sticas por imagen\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # BLOQUE 1: Caracter√≠sticas de color (RGB + HSV)\n",
        "    features_color = extraer_features_color_completas(imagen)\n",
        "    features.extend(features_color)\n",
        "\n",
        "    # BLOQUE 2: Caracter√≠sticas de textura (gradientes y bordes)\n",
        "    features_textura = extraer_features_textura_avanzadas(imagen)\n",
        "    features.extend(features_textura)\n",
        "\n",
        "    # BLOQUE 3: Histograma compacto (reducido para evitar sobreajuste)\n",
        "    # 8 bins por canal = 24 features totales (balance informaci√≥n/dimensionalidad)\n",
        "    histograma = calcular_histograma_color(imagen, bins=8)\n",
        "    features.extend(histograma)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"‚úì Utilidades de extracci√≥n de caracter√≠sticas definidas y documentadas\")\n",
        "print(\"  ‚Üí extraer_estadisticas_basicas(): Estad√≠sticas descriptivas por canal\")\n",
        "print(\"  ‚Üí extraer_features_color_completas(): Caracter√≠sticas RGB + HSV\")\n",
        "print(\"  ‚Üí extraer_features_textura_avanzadas(): Gradientes y detecci√≥n de bordes\")\n",
        "print(\"  ‚Üí calcular_histograma_color(): Histogramas normalizados por canal\")\n",
        "print(\"  ‚Üí extraer_features_completas(): Vector integrado de 46 caracter√≠sticas\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBwKKn9delIB"
      },
      "source": [
        "## UTILIDADES DE MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MabkDIfrelIC"
      },
      "source": [
        "# ===========================================================\n",
        "# UTILIDADES COMPLETAS PARA MACHINE LEARNING EN IM√ÅGENES\n",
        "# ===========================================================\n",
        "\n",
        "def preparar_datos_ml(X, y, test_size=0.2, val_size=0.2):\n",
        "    \"\"\"\n",
        "    Prepara datos para entrenamiento de ML con divisi√≥n estratificada en train/val/test.\n",
        "    Incluye codificaci√≥n de etiquetas y normalizaci√≥n de caracter√≠sticas.\n",
        "\n",
        "    Args:\n",
        "        X (array-like): Matriz de caracter√≠sticas (n_muestras, n_features)\n",
        "        y (array-like): Vector de etiquetas (puede ser string o num√©rico)\n",
        "        test_size (float): Proporci√≥n para conjunto de prueba (0.2 = 20%)\n",
        "        val_size (float): Proporci√≥n de train para validaci√≥n (0.2 = 20% del 80% restante)\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con conjuntos preparados y objetos de preprocesamiento\n",
        "\n",
        "    Conjuntos generados:\n",
        "        - Train: 60% de datos (para entrenar modelo)\n",
        "        - Validation: 20% de datos (para ajuste de hiperpar√°metros)\n",
        "        - Test: 20% de datos (para evaluaci√≥n final)\n",
        "    \"\"\"\n",
        "    # CODIFICACI√ìN DE ETIQUETAS (si son texto)\n",
        "    # Convertir categor√≠as string a n√∫meros enteros\n",
        "    if isinstance(y[0], str):\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "        print(f\"‚úì Etiquetas codificadas: {list(label_encoder.classes_)}\")\n",
        "    else:\n",
        "        y_encoded = y\n",
        "        label_encoder = None\n",
        "        print(\"‚úì Etiquetas num√©ricas detectadas (sin codificaci√≥n)\")\n",
        "\n",
        "    # PRIMERA DIVISI√ìN: Train (80%) + Test (20%)\n",
        "    # stratify=y_encoded mantiene proporci√≥n de clases en ambos conjuntos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded,\n",
        "        test_size=test_size,        # 20% para test\n",
        "        random_state=42,           # Reproducibilidad\n",
        "        stratify=y_encoded         # Mantener distribuci√≥n de clases\n",
        "    )\n",
        "\n",
        "    # SEGUNDA DIVISI√ìN: Train (60%) + Validation (20%)\n",
        "    # val_size se aplica sobre el conjunto de entrenamiento temporal\n",
        "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
        "        X_train, y_train,\n",
        "        test_size=val_size,        # 20% del 80% restante = 16% total ‚Üí ajustado a 25% para obtener 20% final\n",
        "        random_state=42,\n",
        "        stratify=y_train\n",
        "    )\n",
        "\n",
        "    # NORMALIZACI√ìN DE CARACTER√çSTICAS\n",
        "    # StandardScaler: media=0, desviaci√≥n=1 para cada caracter√≠stica\n",
        "    # Importante: fit solo en train, transform en todos los conjuntos\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_final)  # Fit + transform en train\n",
        "    X_val_scaled = scaler.transform(X_val)                # Solo transform en val\n",
        "    X_test_scaled = scaler.transform(X_test)              # Solo transform en test\n",
        "\n",
        "    # PREPARAR RESULTADO\n",
        "    resultado = {\n",
        "        # Conjuntos de datos normalizados\n",
        "        'X_train': X_train_scaled,\n",
        "        'X_val': X_val_scaled,\n",
        "        'X_test': X_test_scaled,\n",
        "        # Etiquetas correspondientes\n",
        "        'y_train': y_train_final,\n",
        "        'y_val': y_val,\n",
        "        'y_test': y_test,\n",
        "        # Objetos de preprocesamiento (para nuevas predicciones)\n",
        "        'scaler': scaler,\n",
        "        'label_encoder': label_encoder\n",
        "    }\n",
        "\n",
        "    # REPORTE DE DIMENSIONES\n",
        "    print(f\"\\n‚úì Conjuntos de datos preparados:\")\n",
        "    print(f\"   ‚Ä¢ Train: {X_train_scaled.shape[0]} muestras ({X_train_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Validation: {X_val_scaled.shape[0]} muestras ({X_val_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Test: {X_test_scaled.shape[0]} muestras ({X_test_scaled.shape[0]/len(X)*100:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Caracter√≠sticas: {X_train_scaled.shape[1]} features por muestra\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def entrenar_modelo_rapido(datos, modelo=None):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de clasificaci√≥n con evaluaci√≥n autom√°tica.\n",
        "    √ötil para prototipos r√°pidos y validaci√≥n de caracter√≠sticas.\n",
        "\n",
        "    Args:\n",
        "        datos (dict): Diccionario retornado por preparar_datos_ml()\n",
        "        modelo (sklearn.base.BaseEstimator): Modelo a entrenar (opcional)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modelo_entrenado, predicciones_val, predicciones_test)\n",
        "\n",
        "    Modelo por defecto: RandomForest (robusto, interpretable, buen rendimiento)\n",
        "    \"\"\"\n",
        "    # Usar RandomForest si no se especifica modelo\n",
        "    # RF es robusto a overfitting y funciona bien sin mucho tuning\n",
        "    if modelo is None:\n",
        "        modelo = RandomForestClassifier(\n",
        "            n_estimators=100,      # 100 √°rboles (balance velocidad/rendimiento)\n",
        "            random_state=42,       # Reproducibilidad\n",
        "            max_depth=10,          # Limitar profundidad (evitar overfitting)\n",
        "            min_samples_split=5    # M√≠nimo de muestras para dividir nodo\n",
        "        )\n",
        "        print(\"‚úì Usando RandomForest por defecto\")\n",
        "    else:\n",
        "        print(f\"‚úì Usando modelo personalizado: {type(modelo).__name__}\")\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    print(\"‚è≥ Entrenando modelo...\")\n",
        "    modelo.fit(datos['X_train'], datos['y_train'])\n",
        "\n",
        "    # PREDICCIONES\n",
        "    # Validaci√≥n: para ajuste de hiperpar√°metros\n",
        "    y_pred_val = modelo.predict(datos['X_val'])\n",
        "    # Test: para evaluaci√≥n final (solo se usa una vez)\n",
        "    y_pred_test = modelo.predict(datos['X_test'])\n",
        "\n",
        "    # M√âTRICAS DE RENDIMIENTO\n",
        "    acc_val = accuracy_score(datos['y_val'], y_pred_val)\n",
        "    acc_test = accuracy_score(datos['y_test'], y_pred_test)\n",
        "\n",
        "    print(f\"\\n‚úì Entrenamiento completado:\")\n",
        "    print(f\"   ‚Ä¢ Accuracy en Validaci√≥n: {acc_val:.3f} ({acc_val*100:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Accuracy en Test: {acc_test:.3f} ({acc_test*100:.1f}%)\")\n",
        "\n",
        "    # Interpretaci√≥n autom√°tica de resultados\n",
        "    if acc_val > 0.9:\n",
        "        print(\"   ‚Üí Excelente rendimiento\")\n",
        "    elif acc_val > 0.8:\n",
        "        print(\"   ‚Üí Buen rendimiento\")\n",
        "    elif acc_val > 0.7:\n",
        "        print(\"   ‚Üí Rendimiento aceptable\")\n",
        "    else:\n",
        "        print(\"   ‚Üí Rendimiento bajo - revisar caracter√≠sticas o modelo\")\n",
        "\n",
        "    # Warning sobre overfitting\n",
        "    if (acc_val - acc_test) > 0.1:\n",
        "        print(\"   ‚ö†Ô∏è  Posible overfitting (gran diferencia val-test)\")\n",
        "\n",
        "    return modelo, y_pred_val, y_pred_test\n",
        "\n",
        "def mostrar_matriz_confusion(y_true, y_pred, labels=None, title=\"Matriz de Confusi√≥n\"):\n",
        "    \"\"\"\n",
        "    Visualiza matriz de confusi√≥n con formato profesional.\n",
        "    Permite identificar errores de clasificaci√≥n por clase.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Etiquetas reales\n",
        "        y_pred (array-like): Etiquetas predichas\n",
        "        labels (list): Nombres de clases para ejes (opcional)\n",
        "        title (str): T√≠tulo del gr√°fico\n",
        "\n",
        "    La matriz muestra:\n",
        "        - Diagonal: Clasificaciones correctas\n",
        "        - Fuera de diagonal: Errores de clasificaci√≥n\n",
        "    \"\"\"\n",
        "    # Calcular matriz de confusi√≥n\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Crear visualizaci√≥n con seaborn (m√°s elegante que matplotlib b√°sico)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Heatmap con anotaciones num√©ricas\n",
        "    sns.heatmap(cm,\n",
        "                annot=True,           # Mostrar n√∫meros en celdas\n",
        "                fmt='d',              # Formato entero\n",
        "                cmap='Blues',         # Escala de colores azul\n",
        "                xticklabels=labels,   # Etiquetas eje X\n",
        "                yticklabels=labels,   # Etiquetas eje Y\n",
        "                cbar_kws={'label': 'N√∫mero de muestras'})\n",
        "\n",
        "    # Configuraci√≥n de ejes y t√≠tulo\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicci√≥n del Modelo', fontsize=12)\n",
        "    plt.ylabel('Valor Real', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calcular m√©tricas adicionales de la matriz\n",
        "    total_muestras = np.sum(cm)\n",
        "    aciertos = np.trace(cm)  # Suma de la diagonal\n",
        "    print(f\"\\nüìä An√°lisis de la matriz:\")\n",
        "    print(f\"   ‚Ä¢ Total de muestras: {total_muestras}\")\n",
        "    print(f\"   ‚Ä¢ Aciertos totales: {aciertos}\")\n",
        "    print(f\"   ‚Ä¢ Errores totales: {total_muestras - aciertos}\")\n",
        "\n",
        "def mostrar_importancia_features(modelo, feature_names=None, top_n=10):\n",
        "    \"\"\"\n",
        "    Visualiza importancia de caracter√≠sticas para modelos basados en √°rboles.\n",
        "    Ayuda a entender qu√© caracter√≠sticas son m√°s relevantes para la clasificaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo entrenado con atributo feature_importances_\n",
        "        feature_names (list): Nombres de caracter√≠sticas (opcional)\n",
        "        top_n (int): N√∫mero de caracter√≠sticas m√°s importantes a mostrar\n",
        "\n",
        "    Solo funciona con: RandomForest, ExtraTrees, GradientBoosting, etc.\n",
        "    \"\"\"\n",
        "    # Verificar si el modelo soporta importancia de caracter√≠sticas\n",
        "    if hasattr(modelo, 'feature_importances_'):\n",
        "        importancias = modelo.feature_importances_\n",
        "\n",
        "        # Obtener √≠ndices de las caracter√≠sticas m√°s importantes\n",
        "        indices = np.argsort(importancias)[-top_n:]  # Top N (orden ascendente)\n",
        "\n",
        "        # Crear nombres por defecto si no se proporcionan\n",
        "        if feature_names is None:\n",
        "            feature_names = [f'Feature_{i}' for i in range(len(importancias))]\n",
        "\n",
        "        # Crear gr√°fico horizontal (mejor para nombres largos)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(range(len(indices)), importancias[indices], color='skyblue', alpha=0.8)\n",
        "\n",
        "        # Configurar ejes\n",
        "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "        plt.xlabel('Importancia Relativa', fontsize=12)\n",
        "        plt.title(f'Top {top_n} Caracter√≠sticas M√°s Importantes', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Agregar valores en las barras\n",
        "        for i, v in enumerate(importancias[indices]):\n",
        "            plt.text(v + 0.001, i, f'{v:.3f}', va='center', fontsize=10)\n",
        "\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Mostrar valores num√©ricos tambi√©n\n",
        "        print(f\"\\nüîç Top {top_n} caracter√≠sticas m√°s importantes:\")\n",
        "        for i, idx in enumerate(reversed(indices)):  # Orden descendente\n",
        "            print(f\"   {i+1:2d}. {feature_names[idx]:<30} {importancias[idx]:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå El modelo {type(modelo).__name__} no soporta importancia de caracter√≠sticas\")\n",
        "        print(\"   Modelos compatibles: RandomForest, ExtraTrees, GradientBoosting\")\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"‚úì Utilidades de Machine Learning definidas y documentadas\")\n",
        "print(\"  ‚Üí preparar_datos_ml(): Divisi√≥n estratificada train/val/test + normalizaci√≥n\")\n",
        "print(\"  ‚Üí entrenar_modelo_rapido(): Entrenamiento con evaluaci√≥n autom√°tica\")\n",
        "print(\"  ‚Üí mostrar_matriz_confusion(): Visualizaci√≥n profesional de errores\")\n",
        "print(\"  ‚Üí mostrar_importancia_features(): An√°lisis de relevancia de caracter√≠sticas\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk--75yjelIC"
      },
      "source": [
        "## UTILIDADES DE VISUALIZACI√ìN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L74aS5PrelIC"
      },
      "source": [
        "# ====================================================\n",
        "# UTILIDADES AVANZADAS DE VISUALIZACI√ìN\n",
        "# ====================================================\n",
        "\n",
        "def crear_grid_imagenes(imagenes, titulos=None, filas=2, figsize=(15, 8)):\n",
        "    \"\"\"\n",
        "    Crea un grid organizado de im√°genes para comparaci√≥n visual.\n",
        "    √ötil para mostrar m√∫ltiples im√°genes en una sola figura.\n",
        "\n",
        "    Args:\n",
        "        imagenes (list): Lista de arrays de im√°genes\n",
        "        titulos (list): Lista de t√≠tulos para cada imagen (opcional)\n",
        "        filas (int): N√∫mero de filas en el grid\n",
        "        figsize (tuple): Tama√±o de la figura (ancho, alto)\n",
        "\n",
        "    Maneja autom√°ticamente:\n",
        "        - Im√°genes en escala de grises (2D arrays)\n",
        "        - Im√°genes en color (3D arrays)\n",
        "        - Grids irregulares (espacios vac√≠os)\n",
        "    \"\"\"\n",
        "    n_imagenes = len(imagenes)\n",
        "    # Calcular columnas necesarias basado en n√∫mero de im√°genes y filas\n",
        "    columnas = int(np.ceil(n_imagenes / filas))\n",
        "\n",
        "    # Crear subplot grid\n",
        "    fig, axes = plt.subplots(filas, columnas, figsize=figsize)\n",
        "\n",
        "    # Manejar caso especial de una sola imagen\n",
        "    if n_imagenes == 1:\n",
        "        axes = [axes]\n",
        "    elif filas == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    elif columnas == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    # Aplanar array de axes para f√°cil iteraci√≥n\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Mostrar cada imagen\n",
        "    for i, img in enumerate(imagenes):\n",
        "        # Detectar si es escala de grises o color\n",
        "        if len(img.shape) == 2:  # Escala de grises\n",
        "            axes[i].imshow(img, cmap='gray')\n",
        "        else:  # Color (RGB)\n",
        "            axes[i].imshow(img)\n",
        "\n",
        "        # Agregar t√≠tulo si se proporciona\n",
        "        if titulos and i < len(titulos):\n",
        "            axes[i].set_title(titulos[i], fontsize=12)\n",
        "\n",
        "        # Ocultar ejes para mejor visualizaci√≥n\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Ocultar axes sobrantes en caso de grid irregular\n",
        "    for i in range(n_imagenes, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def mostrar_antes_despues(img_original, img_procesada, titulo_original=\"Original\", titulo_procesada=\"Procesada\"):\n",
        "    \"\"\"\n",
        "    Muestra comparaci√≥n lado a lado de imagen original vs procesada.\n",
        "    Perfecto para visualizar el efecto de operaciones de procesamiento.\n",
        "\n",
        "    Args:\n",
        "        img_original (numpy.ndarray): Imagen antes del procesamiento\n",
        "        img_procesada (numpy.ndarray): Imagen despu√©s del procesamiento\n",
        "        titulo_original (str): T√≠tulo para imagen original\n",
        "        titulo_procesada (str): T√≠tulo para imagen procesada\n",
        "    \"\"\"\n",
        "    # Crear subplot con 2 columnas\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Mostrar imagen original\n",
        "    ax1.imshow(img_original)\n",
        "    ax1.set_title(titulo_original, fontsize=14, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Mostrar imagen procesada (detectar si es escala de grises)\n",
        "    if len(img_procesada.shape) == 2:\n",
        "        ax2.imshow(img_procesada, cmap='gray')\n",
        "    else:\n",
        "        ax2.imshow(img_procesada)\n",
        "    ax2.set_title(titulo_procesada, fontsize=14, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def crear_dashboard_imagen(imagen, mostrar_canales=True, mostrar_histograma=True, mostrar_estadisticas=True):\n",
        "    \"\"\"\n",
        "    Crea un dashboard completo de an√°lisis visual de imagen.\n",
        "    Combina m√∫ltiples visualizaciones en una sola figura integral.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen RGB a analizar\n",
        "        mostrar_canales (bool): Mostrar separaci√≥n de canales RGB\n",
        "        mostrar_histograma (bool): Mostrar histograma de intensidades\n",
        "        mostrar_estadisticas (bool): Mostrar panel de estad√≠sticas\n",
        "\n",
        "    Genera:\n",
        "        - Imagen original\n",
        "        - Canales RGB separados\n",
        "        - Histograma de distribuci√≥n de colores\n",
        "        - Panel de estad√≠sticas descriptivas\n",
        "    \"\"\"\n",
        "    # Crear figura grande con subplot grid\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Imagen original (posici√≥n principal)\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title('Imagen Original', fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    if mostrar_canales and len(imagen.shape) == 3:\n",
        "        # Canales RGB individuales\n",
        "        canales = ['Rojo', 'Verde', 'Azul']\n",
        "        cmaps = ['Reds', 'Greens', 'Blues']\n",
        "\n",
        "        for i in range(3):\n",
        "            ax = plt.subplot(3, 3, i + 2)\n",
        "            plt.imshow(imagen[:,:,i], cmap=cmaps[i])\n",
        "            plt.title(f'Canal {canales[i]}', fontsize=12)\n",
        "            plt.axis('off')\n",
        "\n",
        "    if mostrar_histograma:\n",
        "        # Histograma de distribuci√≥n de colores\n",
        "        ax5 = plt.subplot(3, 3, 5)\n",
        "        if len(imagen.shape) == 3:\n",
        "            colors = ['red', 'green', 'blue']\n",
        "            # Histograma superpuesto para cada canal\n",
        "            for i in range(3):\n",
        "                plt.hist(imagen[:,:,i].flatten(), bins=50, alpha=0.6,\n",
        "                        color=colors[i], label=canales[i])\n",
        "            plt.legend()\n",
        "        else:\n",
        "            plt.hist(imagen.flatten(), bins=50, alpha=0.7, color='gray')\n",
        "\n",
        "        plt.title('Histograma de Intensidades', fontsize=12)\n",
        "        plt.xlabel('Intensidad')\n",
        "        plt.ylabel('Frecuencia')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "    if mostrar_estadisticas:\n",
        "        # Panel de estad√≠sticas descriptivas\n",
        "        ax6 = plt.subplot(3, 3, 6)\n",
        "        ax6.axis('off')  # Sin ejes para texto puro\n",
        "\n",
        "        # Compilar texto estad√≠stico\n",
        "        stats_text = \"üìä ESTAD√çSTICAS:\\n\\n\"\n",
        "        stats_text += f\"üìê Dimensiones: {imagen.shape}\\n\"\n",
        "        stats_text += f\"üî¢ Tipo de datos: {imagen.dtype}\\n\"\n",
        "        stats_text += f\"üìâ Rango: [{imagen.min():.3f}, {imagen.max():.3f}]\\n\"\n",
        "        stats_text += f\"üìä Media global: {imagen.mean():.3f}\\n\"\n",
        "        stats_text += f\"üìà Desv. est√°ndar: {imagen.std():.3f}\\n\\n\"\n",
        "\n",
        "        # Estad√≠sticas por canal si es color\n",
        "        if len(imagen.shape) == 3:\n",
        "            stats_text += \"üé® POR CANAL:\\n\"\n",
        "            canales_nombres = ['üî¥ Rojo', 'üü¢ Verde', 'üîµ Azul']\n",
        "            for i in range(3):\n",
        "                canal_mean = imagen[:,:,i].mean()\n",
        "                canal_std = imagen[:,:,i].std()\n",
        "                stats_text += f\"{canales_nombres[i]}: Œº={canal_mean:.3f}, œÉ={canal_std:.3f}\\n\"\n",
        "\n",
        "        # Mostrar texto con formato monoespaciado\n",
        "        plt.text(0.05, 0.95, stats_text, fontsize=10,\n",
        "                verticalalignment='top', fontfamily='monospace',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "    plt.suptitle('Dashboard de An√°lisis de Imagen', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"‚úì Utilidades de visualizaci√≥n definidas y documentadas\")\n",
        "print(\"  ‚Üí crear_grid_imagenes(): Grid organizado para m√∫ltiples im√°genes\")\n",
        "print(\"  ‚Üí mostrar_antes_despues(): Comparaci√≥n lado a lado\")\n",
        "print(\"  ‚Üí crear_dashboard_imagen(): Dashboard integral de an√°lisis\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8-cVYqHelIC"
      },
      "source": [
        "## PLANTILLAS R√ÅPIDAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzVe9CcTelIC"
      },
      "source": [
        "# =============================================\n",
        "# PLANTILLAS R√ÅPIDAS PARA TAREAS COMUNES\n",
        "# =============================================\n",
        "\n",
        "def analisis_rapido_imagen(path_imagen):\n",
        "    \"\"\"\n",
        "    PLANTILLA 1: An√°lisis completo y r√°pido de una imagen individual.\n",
        "    Combina carga, an√°lisis estad√≠stico, visualizaci√≥n y conversi√≥n de espacios.\n",
        "\n",
        "    Args:\n",
        "        path_imagen (str): Ruta al archivo de imagen\n",
        "\n",
        "    Returns:\n",
        "        tuple: (imagen_cargada, dict_espacios_color) o None si hay error\n",
        "\n",
        "    Procesos incluidos:\n",
        "        - Carga segura con redimensionamiento est√°ndar\n",
        "        - An√°lisis estad√≠stico completo\n",
        "        - Dashboard visual integrado\n",
        "        - Conversi√≥n a m√∫ltiples espacios de color\n",
        "        - Visualizaci√≥n comparativa de espacios\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Iniciando an√°lisis r√°pido de imagen...\")\n",
        "\n",
        "    # PASO 1: Cargar imagen con tama√±o est√°ndar para an√°lisis\n",
        "    imagen = cargar_imagen_segura(path_imagen, target_size=(256, 256))\n",
        "    if imagen is None:\n",
        "        print(\"‚ùå Error: No se pudo cargar la imagen\")\n",
        "        return None\n",
        "\n",
        "    print(\"‚úì Imagen cargada correctamente\")\n",
        "\n",
        "    # PASO 2: An√°lisis estad√≠stico b√°sico\n",
        "    print(\"\\nüìä Informaci√≥n estad√≠stica:\")\n",
        "    mostrar_imagen_info(imagen, \"An√°lisis R√°pido\")\n",
        "\n",
        "    # PASO 3: Dashboard visual completo\n",
        "    print(\"\\nüìà Generando dashboard visual...\")\n",
        "    crear_dashboard_imagen(imagen)\n",
        "\n",
        "    # PASO 4: Conversi√≥n a m√∫ltiples espacios de color\n",
        "    print(\"\\nüé® Convirtiendo espacios de color...\")\n",
        "    espacios = convertir_espacios_color(imagen)\n",
        "\n",
        "    # PASO 5: Visualizaci√≥n comparativa de espacios\n",
        "    imagenes_espacios = [espacios['rgb'], espacios['hsv'], espacios['gray']]\n",
        "    titulos_espacios = ['RGB (Original)', 'HSV (Tono-Saturaci√≥n)', 'Escala de Grises']\n",
        "    crear_grid_imagenes(imagenes_espacios, titulos_espacios, filas=1)\n",
        "\n",
        "    print(\"‚úÖ An√°lisis completado exitosamente\")\n",
        "    return imagen, espacios\n",
        "\n",
        "def pipeline_dataset_completo(carpeta_imagenes, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    PLANTILLA 2: Pipeline completo para procesamiento de dataset de im√°genes.\n",
        "    Desde carga masiva hasta modelo entrenado y evaluado.\n",
        "\n",
        "    Args:\n",
        "        carpeta_imagenes (str): Ruta a carpeta con subcarpetas por categor√≠a\n",
        "        target_size (tuple): Tama√±o objetivo para todas las im√°genes\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario completo con im√°genes, caracter√≠sticas, datos ML y modelo\n",
        "\n",
        "    Estructura esperada de carpetas:\n",
        "        carpeta_imagenes/\n",
        "        ‚îú‚îÄ‚îÄ categoria1/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ imagen1.jpg\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ imagen2.jpg\n",
        "        ‚îî‚îÄ‚îÄ categoria2/\n",
        "            ‚îú‚îÄ‚îÄ imagen3.jpg\n",
        "            ‚îî‚îÄ‚îÄ imagen4.jpg\n",
        "    \"\"\"\n",
        "    print(\"üîÑ Iniciando pipeline completo de dataset...\")\n",
        "\n",
        "    imagenes = []\n",
        "    etiquetas = []\n",
        "\n",
        "    # PASO 1: Carga masiva por categor√≠as\n",
        "    print(\"üìÅ Cargando im√°genes por categor√≠a:\")\n",
        "    for categoria in os.listdir(carpeta_imagenes):\n",
        "        categoria_path = os.path.join(carpeta_imagenes, categoria)\n",
        "\n",
        "        # Verificar que sea directorio\n",
        "        if os.path.isdir(categoria_path):\n",
        "            print(f\"   üîç Procesando categor√≠a '{categoria}'...\")\n",
        "            contador_categoria = 0\n",
        "\n",
        "            # Procesar cada imagen en la categor√≠a\n",
        "            for archivo in os.listdir(categoria_path):\n",
        "                # Verificar extensiones de imagen v√°lidas\n",
        "                if archivo.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                    path_completo = os.path.join(categoria_path, archivo)\n",
        "                    img = cargar_imagen_segura(path_completo, target_size)\n",
        "\n",
        "                    if img is not None:\n",
        "                        imagenes.append(img)\n",
        "                        etiquetas.append(categoria)\n",
        "                        contador_categoria += 1\n",
        "\n",
        "            print(f\"      ‚úì {contador_categoria} im√°genes cargadas\")\n",
        "\n",
        "    total_imagenes = len(imagenes)\n",
        "    print(f\"\\nüìä Total: {total_imagenes} im√°genes cargadas desde {len(set(etiquetas))} categor√≠as\")\n",
        "\n",
        "    if total_imagenes == 0:\n",
        "        print(\"‚ùå Error: No se encontraron im√°genes v√°lidas\")\n",
        "        return None\n",
        "\n",
        "    # PASO 2: Conversi√≥n a arrays NumPy\n",
        "    X = np.array(imagenes)\n",
        "    y = np.array(etiquetas)\n",
        "\n",
        "    # PASO 3: Extracci√≥n masiva de caracter√≠sticas\n",
        "    print(f\"\\nüéØ Extrayendo caracter√≠sticas de {total_imagenes} im√°genes...\")\n",
        "    features = []\n",
        "\n",
        "    # Barra de progreso simulada\n",
        "    for i, img in enumerate(imagenes):\n",
        "        feat = extraer_features_completas(img)\n",
        "        features.append(feat)\n",
        "\n",
        "        # Mostrar progreso cada 10%\n",
        "        if (i + 1) % max(1, total_imagenes // 10) == 0:\n",
        "            progreso = (i + 1) / total_imagenes * 100\n",
        "            print(f\"      üìà Progreso: {progreso:.0f}% ({i + 1}/{total_imagenes})\")\n",
        "\n",
        "    X_features = np.array(features)\n",
        "    print(f\"‚úì Caracter√≠sticas extra√≠das: {X_features.shape[1]} features por imagen\")\n",
        "\n",
        "    # PASO 4: Preparaci√≥n para ML\n",
        "    print(f\"\\nü§ñ Preparando datos para Machine Learning...\")\n",
        "    datos_ml = preparar_datos_ml(X_features, y)\n",
        "\n",
        "    # PASO 5: Entrenamiento y evaluaci√≥n r√°pida\n",
        "    print(f\"\\nüé≤ Entrenamiento de modelo de validaci√≥n...\")\n",
        "    modelo, pred_val, pred_test = entrenar_modelo_rapido(datos_ml)\n",
        "\n",
        "    # PASO 6: Compilar resultados\n",
        "    resultado = {\n",
        "        'imagenes_originales': X,           # Arrays de im√°genes\n",
        "        'etiquetas': y,                     # Etiquetas de categor√≠as\n",
        "        'caracteristicas': X_features,      # Features extra√≠dos\n",
        "        'datos_ml': datos_ml,              # Conjuntos train/val/test preparados\n",
        "        'modelo': modelo,                   # Modelo entrenado\n",
        "        'predicciones_val': pred_val,      # Predicciones en validaci√≥n\n",
        "        'predicciones_test': pred_test     # Predicciones en test\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüéâ Pipeline completado exitosamente!\")\n",
        "    print(f\"   üìù Datos listos para an√°lisis avanzado\")\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def segmentacion_rapida(imagen, metodo='kmeans', **kwargs):\n",
        "    \"\"\"\n",
        "    PLANTILLA 3: Segmentaci√≥n r√°pida con m√∫ltiples algoritmos disponibles.\n",
        "    Permite experimentar f√°cilmente con diferentes t√©cnicas de segmentaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        imagen (numpy.ndarray): Imagen a segmentar\n",
        "        metodo (str): M√©todo de segmentaci√≥n ('kmeans' o 'color_range')\n",
        "        **kwargs: Par√°metros espec√≠ficos del m√©todo\n",
        "\n",
        "    Returns:\n",
        "        tuple: (resultado_segmentacion, modelo_o_parametros)\n",
        "\n",
        "    M√©todos disponibles:\n",
        "        - 'kmeans': Clustering autom√°tico en espacio HSV\n",
        "          Par√°metros: n_clusters=5\n",
        "        - 'color_range': Segmentaci√≥n por rango de color HSV\n",
        "          Par√°metros: h_min=0.0, h_max=0.1, s_min=0.2, v_min=0.2\n",
        "    \"\"\"\n",
        "    print(f\"üéØ Iniciando segmentaci√≥n usando m√©todo '{metodo}'...\")\n",
        "\n",
        "    if metodo == 'kmeans':\n",
        "        # SEGMENTACI√ìN POR CLUSTERING\n",
        "        n_clusters = kwargs.get('n_clusters', 5)\n",
        "        print(f\"   üî¨ Aplicando K-means con {n_clusters} clusters...\")\n",
        "\n",
        "        segmentacion, modelo = segmentar_por_color_hsv_auto(imagen, n_clusters)\n",
        "        parametros = {'metodo': 'kmeans', 'n_clusters': n_clusters}\n",
        "\n",
        "    elif metodo == 'color_range':\n",
        "        # SEGMENTACI√ìN POR RANGO DE COLOR\n",
        "        h_min = kwargs.get('h_min', 0.0)\n",
        "        h_max = kwargs.get('h_max', 0.1)\n",
        "        s_min = kwargs.get('s_min', 0.2)\n",
        "        v_min = kwargs.get('v_min', 0.2)\n",
        "\n",
        "        print(f\"   üåà Segmentando rango HSV: H[{h_min:.2f}-{h_max:.2f}], S‚â•{s_min:.2f}, V‚â•{v_min:.2f}\")\n",
        "\n",
        "        imagen_hsv = color.rgb2hsv(imagen)\n",
        "        segmentacion = crear_mascara_color_rango(imagen_hsv, h_min, h_max, s_min, v_min)\n",
        "\n",
        "        modelo = None\n",
        "        parametros = {\n",
        "            'metodo': 'color_range',\n",
        "            'h_min': h_min, 'h_max': h_max,\n",
        "            's_min': s_min, 'v_min': v_min\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå Error: M√©todo '{metodo}' no reconocido\")\n",
        "        print(\"   üí° M√©todos disponibles: 'kmeans', 'color_range'\")\n",
        "        return None, None\n",
        "\n",
        "    # Mostrar resultados comparativos\n",
        "    print(\"   üìä Generando visualizaci√≥n comparativa...\")\n",
        "    titulo_resultado = f\"Segmentaci√≥n ({metodo.upper()})\"\n",
        "    mostrar_antes_despues(imagen, segmentacion, \"Original\", titulo_resultado)\n",
        "\n",
        "    # Estad√≠sticas de la segmentaci√≥n\n",
        "    if metodo == 'kmeans':\n",
        "        regiones_unicas = len(np.unique(segmentacion))\n",
        "        print(f\"   ‚úì {regiones_unicas} regiones identificadas\")\n",
        "    else:\n",
        "        pixeles_segmentados = np.sum(segmentacion)\n",
        "        total_pixeles = segmentacion.size\n",
        "        porcentaje = (pixeles_segmentados / total_pixeles) * 100\n",
        "        print(f\"   ‚úì {pixeles_segmentados} p√≠xeles segmentados ({porcentaje:.1f}% del total)\")\n",
        "\n",
        "    print(\"üéØ Segmentaci√≥n completada\")\n",
        "    return segmentacion, {'modelo': modelo, 'parametros': parametros}\n",
        "\n",
        "# Mensajes informativos para el usuario\n",
        "print(\"‚úì Plantillas r√°pidas definidas y documentadas\")\n",
        "print(\"\\nüöÄ Plantillas disponibles:\")\n",
        "print(\"   1Ô∏è‚É£  analisis_rapido_imagen(path) - An√°lisis integral de imagen individual\")\n",
        "print(\"   2Ô∏è‚É£  pipeline_dataset_completo(carpeta) - Procesamiento completo de dataset\")\n",
        "print(\"   3Ô∏è‚É£  segmentacion_rapida(imagen, metodo, **params) - Segmentaci√≥n experimental\")\n",
        "print(\"\\nüí° Cada plantilla incluye mensajes de progreso y manejo de errores\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eXNmoIelID"
      },
      "source": [
        "## EJEMPLOS DE USO\n",
        "\n",
        "### Ejemplo 1: An√°lisis r√°pido de imagen\n",
        "```python\n",
        "# An√°lisis completo con una sola funci√≥n\n",
        "imagen, espacios = analisis_rapido_imagen('mi_imagen.jpg')\n",
        "\n",
        "# Acceder a diferentes espacios de color\n",
        "img_hsv = espacios['hsv']\n",
        "img_gray = espacios['gray']\n",
        "```\n",
        "\n",
        "### Ejemplo 2: Segmentaci√≥n por color\n",
        "```python\n",
        "# Segmentaci√≥n autom√°tica con K-means\n",
        "seg, info = segmentacion_rapida(imagen, 'kmeans', n_clusters=4)\n",
        "\n",
        "# Segmentaci√≥n por rango de color espec√≠fico (rojos)\n",
        "seg, info = segmentacion_rapida(imagen, 'color_range',\n",
        "                               h_min=0.9, h_max=1.0,\n",
        "                               s_min=0.5, v_min=0.3)\n",
        "```\n",
        "\n",
        "### Ejemplo 3: Pipeline completo de dataset\n",
        "```python\n",
        "# Procesamiento autom√°tico de dataset completo\n",
        "resultado = pipeline_dataset_completo('mi_dataset/')\n",
        "\n",
        "# Acceder a componentes individuales\n",
        "modelo = resultado['modelo']\n",
        "datos_ml = resultado['datos_ml']\n",
        "caracteristicas = resultado['caracteristicas']\n",
        "\n",
        "# An√°lisis avanzado\n",
        "mostrar_matriz_confusion(datos_ml['y_test'],\n",
        "                        resultado['predicciones_test'])\n",
        "```\n",
        "\n",
        "### Ejemplo 4: Extracci√≥n manual de caracter√≠sticas\n",
        "```python\n",
        "# Cargar y preparar imagen\n",
        "img = cargar_imagen_segura('imagen.jpg', target_size=(128, 128))\n",
        "\n",
        "# Extraer diferentes tipos de caracter√≠sticas\n",
        "features_completas = extraer_features_completas(img)  # 46 caracter√≠sticas\n",
        "features_color = extraer_features_color_completas(img)  # 15 caracter√≠sticas\n",
        "features_textura = extraer_features_textura_avanzadas(img)  # 7 caracter√≠sticas\n",
        "\n",
        "print(f\"Caracter√≠sticas extra√≠das: {len(features_completas)} total\")\n",
        "```\n",
        "\n",
        "### Ejemplo 5: Visualizaci√≥n avanzada\n",
        "```python\n",
        "# Grid de m√∫ltiples im√°genes\n",
        "imagenes = [img1, img2, img3, img4]\n",
        "titulos = ['Original', 'Filtrada', 'Segmentada', 'Resultado']\n",
        "crear_grid_imagenes(imagenes, titulos, filas=2)\n",
        "\n",
        "# Dashboard completo\n",
        "crear_dashboard_imagen(imagen,\n",
        "                      mostrar_canales=True,\n",
        "                      mostrar_histograma=True,\n",
        "                      mostrar_estadisticas=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ¬°Utilidades listas para usar!\n",
        "\n",
        "**üéØ Para usar en laboratorios:**\n",
        "1. Ejecuta la celda de **importaciones** al inicio\n",
        "2. Ejecuta las celdas de **utilidades** que necesites\n",
        "3. Usa las **plantillas r√°pidas** para tareas comunes\n",
        "4. Consulta el **glosario** para t√©rminos t√©cnicos\n",
        "\n",
        "**üí° Consejos:**\n",
        "- Todas las funciones incluyen documentaci√≥n detallada\n",
        "- Los mensajes de progreso te mantienen informado\n",
        "- Manejo robusto de errores en todas las operaciones\n",
        "- Par√°metros por defecto optimizados para la mayor√≠a de casos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671x6Ym5elID"
      },
      "source": [
        "---\n",
        "\n",
        "# GLOSARIO T√âCNICO\n",
        "\n",
        "## T√©rminos de Procesamiento de Im√°genes\n",
        "\n",
        "**Array/Arreglo**: Estructura de datos multidimensional de NumPy. Para im√°genes RGB: shape (altura, ancho, 3)\n",
        "\n",
        "**BGR vs RGB**: Orden de canales de color. OpenCV usa BGR (Azul-Verde-Rojo), PIL/matplotlib usan RGB (Rojo-Verde-Azul)\n",
        "\n",
        "**Bounding Box**: Rect√°ngulo m√≠nimo que contiene completamente un objeto detectado\n",
        "\n",
        "**Canal**: Una de las componentes de color en una imagen (ej: R, G, B en RGB o H, S, V en HSV)\n",
        "\n",
        "**Clustering**: T√©cnica de agrupamiento que divide datos en grupos similares sin supervisi√≥n\n",
        "\n",
        "**Componentes Conectados**: Regiones de p√≠xeles conectados que comparten caracter√≠sticas similares\n",
        "\n",
        "**Elemento Estructurante/Kernel**: Matriz peque√±a usada en operaciones morfol√≥gicas (ej: c√≠rculo, cuadrado)\n",
        "\n",
        "**Escala de Grises**: Imagen con un solo canal representando intensidad de luminancia (0=negro, 1=blanco)\n",
        "\n",
        "**Espacio de Color**: Sistema de coordenadas para representar colores (RGB, HSV, LAB, etc.)\n",
        "\n",
        "**M√°scara Binaria**: Imagen de 2 valores (0 y 1) que indica qu√© p√≠xeles pertenecen a una regi√≥n de inter√©s\n",
        "\n",
        "**Normalizaci√≥n**: Proceso de escalar valores a un rango est√°ndar (ej: [0,255] ‚Üí [0,1])\n",
        "\n",
        "**P√≠xel**: Unidad m√≠nima de una imagen digital. Contiene valores de intensidad para cada canal de color\n",
        "\n",
        "**Segmentaci√≥n**: Proceso de dividir una imagen en regiones homog√©neas o objetos de inter√©s\n",
        "\n",
        "**Umbralizaci√≥n/Thresholding**: T√©cnica que convierte imagen en escala de grises a binaria usando un valor umbral\n",
        "\n",
        "## Espacios de Color\n",
        "\n",
        "**RGB (Red-Green-Blue)**:\n",
        "- R: Intensidad de rojo [0,1]\n",
        "- G: Intensidad de verde [0,1]  \n",
        "- B: Intensidad de azul [0,1]\n",
        "- Aditivo (suma colores para crear blanco)\n",
        "\n",
        "**HSV (Hue-Saturation-Value)**:\n",
        "- H: Tono/Matiz [0,1] (tipo de color: rojo‚âà0, verde‚âà0.33, azul‚âà0.67)\n",
        "- S: Saturaci√≥n [0,1] (pureza del color: 0=gris, 1=color puro)\n",
        "- V: Valor/Brillo [0,1] (intensidad luminosa: 0=negro, 1=brillante)\n",
        "\n",
        "**LAB (L*a*b*)**:\n",
        "- L: Luminancia [0,100] (brillo perceptual)\n",
        "- a: Verde (-) a Magenta (+)\n",
        "- b: Azul (-) a Amarillo (+)\n",
        "- Perceptualmente uniforme (diferencias num√©ricas = diferencias visuales)\n",
        "\n",
        "## Operaciones Morfol√≥gicas\n",
        "\n",
        "**Erosi√≥n**: Reduce el tama√±o de regiones blancas (adelgaza objetos)\n",
        "\n",
        "**Dilataci√≥n**: Expande el tama√±o de regiones blancas (engrosa objetos)\n",
        "\n",
        "**Apertura (Opening)**: Erosi√≥n seguida de dilataci√≥n (elimina ruido peque√±o)\n",
        "\n",
        "**Cierre (Closing)**: Dilataci√≥n seguida de erosi√≥n (cierra huecos peque√±os)\n",
        "\n",
        "## Filtros y Detecci√≥n de Bordes\n",
        "\n",
        "**Filtro Sobel**: Detecta gradientes (cambios de intensidad) en direcciones horizontal y vertical\n",
        "\n",
        "**Detector Canny**: Algoritmo avanzado de detecci√≥n de bordes con supresi√≥n de no-m√°ximos\n",
        "\n",
        "**Gradiente**: Medida del cambio de intensidad entre p√≠xeles vecinos\n",
        "\n",
        "## Caracter√≠sticas (Features) para ML\n",
        "\n",
        "**Estad√≠sticas de Primer Orden**: Media, desviaci√≥n est√°ndar, mediana (distribuci√≥n de intensidades)\n",
        "\n",
        "**Estad√≠sticas de Segundo Orden**: Correlaci√≥n, contraste, homogeneidad (relaciones espaciales)\n",
        "\n",
        "**Histograma**: Distribuci√≥n de frecuencias de intensidades de p√≠xeles\n",
        "\n",
        "**Textura**: Patrones espaciales de variaci√≥n de intensidad (rugosidad, suavidad, regularidad)\n",
        "\n",
        "## Machine Learning\n",
        "\n",
        "**Conjunto de Entrenamiento (Train)**: Datos usados para ense√±ar al modelo (‚âà60%)\n",
        "\n",
        "**Conjunto de Validaci√≥n (Val)**: Datos para ajustar hiperpar√°metros y evitar overfitting (‚âà20%)\n",
        "\n",
        "**Conjunto de Prueba (Test)**: Datos para evaluaci√≥n final del modelo (‚âà20%)\n",
        "\n",
        "**Caracter√≠sticas/Features**: Variables num√©ricas que describen cada muestra (ej: color promedio, textura)\n",
        "\n",
        "**Etiquetas/Labels**: Categor√≠as o valores objetivo que el modelo debe predecir\n",
        "\n",
        "**Matriz de Confusi√≥n**: Tabla que muestra aciertos y errores de clasificaci√≥n por cada clase\n",
        "\n",
        "**Overfitting**: Modelo que memoriza datos de entrenamiento pero no generaliza a datos nuevos\n",
        "\n",
        "**RandomForest**: Algoritmo que combina m√∫ltiples √°rboles de decisi√≥n para mayor robustez\n",
        "\n",
        "**Validaci√≥n Estratificada**: Divisi√≥n que mantiene la proporci√≥n de cada clase en todos los conjuntos\n",
        "\n",
        "## M√©tricas de Evaluaci√≥n\n",
        "\n",
        "**Accuracy (Exactitud)**: Proporci√≥n de predicciones correctas sobre el total\n",
        "\n",
        "**Precisi√≥n**: De las predicciones positivas, cu√°ntas fueron correctas\n",
        "\n",
        "**Recall (Sensibilidad)**: De los casos positivos reales, cu√°ntos fueron detectados\n",
        "\n",
        "**F1-Score**: Media arm√≥nica entre precisi√≥n y recall\n",
        "\n",
        "## Bibliotecas Python\n",
        "\n",
        "**NumPy**: Operaciones num√©ricas y arrays multidimensionales eficientes\n",
        "\n",
        "**PIL (Pillow)**: Carga, manipulaci√≥n y guardado de im√°genes en m√∫ltiples formatos\n",
        "\n",
        "**OpenCV (cv2)**: Biblioteca completa de computer vision (¬°usa formato BGR!)\n",
        "\n",
        "**scikit-image**: Algoritmos especializados de procesamiento de im√°genes\n",
        "\n",
        "**scikit-learn**: Herramientas de machine learning y an√°lisis de datos\n",
        "\n",
        "**matplotlib**: Creaci√≥n de gr√°ficos y visualizaci√≥n de im√°genes\n",
        "\n",
        "**seaborn**: Visualizaciones estad√≠sticas avanzadas basadas en matplotlib\n",
        "\n",
        "---\n",
        "\n",
        "## Referencias R√°pidas de Rangos\n",
        "\n",
        "### Rangos de Tono (H) en HSV para Colores Comunes:\n",
        "- **Rojo**: 0.0-0.1 y 0.9-1.0 (est√° en ambos extremos)\n",
        "- **Naranja**: 0.05-0.15\n",
        "- **Amarillo**: 0.15-0.25  \n",
        "- **Verde**: 0.25-0.45\n",
        "- **Cian**: 0.45-0.55\n",
        "- **Azul**: 0.55-0.75\n",
        "- **Magenta**: 0.75-0.9\n",
        "\n",
        "### Valores T√≠picos de Saturaci√≥n (S) y Valor (V):\n",
        "- **Colores vivos**: S > 0.5, V > 0.5\n",
        "- **Colores pasteles**: S < 0.5, V > 0.7\n",
        "- **Colores oscuros**: V < 0.3 (independiente de S)\n",
        "- **Grises**: S < 0.2 (independiente de V)\n",
        "\n",
        "### Tama√±os de Kernel Recomendados:\n",
        "- **Ruido peque√±o**: kernel = 2-3 p√≠xeles\n",
        "- **Detalles medianos**: kernel = 5-7 p√≠xeles  \n",
        "- **Objetos grandes**: kernel = 10+ p√≠xeles\n",
        "\n",
        "---\n",
        "\n",
        "## ¬°Todo listo para el laboratorio integrador!\n",
        "\n",
        "Este cuaderno te proporciona todas las herramientas necesarias para trabajar eficientemente en el procesamiento de im√°genes y machine learning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}